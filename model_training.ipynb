{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15667551",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:50.655157Z",
     "iopub.status.busy": "2022-12-12T17:31:50.654619Z",
     "iopub.status.idle": "2022-12-12T17:31:50.665089Z",
     "shell.execute_reply": "2022-12-12T17:31:50.664227Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033491,
     "end_time": "2022-12-12T17:31:50.667201",
     "exception": false,
     "start_time": "2022-12-12T17:31:50.633710",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd70952d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:50.703958Z",
     "iopub.status.busy": "2022-12-12T17:31:50.703660Z",
     "iopub.status.idle": "2022-12-12T17:31:50.917044Z",
     "shell.execute_reply": "2022-12-12T17:31:50.916068Z"
    },
    "papermill": {
     "duration": 0.234064,
     "end_time": "2022-12-12T17:31:50.919368",
     "exception": false,
     "start_time": "2022-12-12T17:31:50.685304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/mlkaggle/vuong_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc2ae44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:50.957534Z",
     "iopub.status.busy": "2022-12-12T17:31:50.955923Z",
     "iopub.status.idle": "2022-12-12T17:31:50.961286Z",
     "shell.execute_reply": "2022-12-12T17:31:50.960451Z"
    },
    "papermill": {
     "duration": 0.025458,
     "end_time": "2022-12-12T17:31:50.963210",
     "exception": false,
     "start_time": "2022-12-12T17:31:50.937752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['label'] = df['label'].replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3327c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:50.999504Z",
     "iopub.status.busy": "2022-12-12T17:31:50.998640Z",
     "iopub.status.idle": "2022-12-12T17:31:51.021778Z",
     "shell.execute_reply": "2022-12-12T17:31:51.020638Z"
    },
    "papermill": {
     "duration": 0.04319,
     "end_time": "2022-12-12T17:31:51.023854",
     "exception": false,
     "start_time": "2022-12-12T17:31:50.980664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>len</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>xôi dẻo đồ_ăn đậm vị hộp xôi được lót lá trông...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>gọi ship 1 xuất cari gà bánh naan và 3 miếng g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>thời_tiết lạnh như này cả nhà rủ nhau đến lega...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>em có đọc review thấy mng bảo trà sữa nướng đề...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>đồ_ăn rất ngon nhà_hàng cũng rất đẹp tất_cả đề...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>9068</td>\n",
       "      <td>30</td>\n",
       "      <td>thực_sự mà nói thấy mọi người đánh_giá nhiều q...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9065</th>\n",
       "      <td>9069</td>\n",
       "      <td>134</td>\n",
       "      <td>lẩu thái tômyum đc 19 lò_đúc hbt hn theo đánh_...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>9070</td>\n",
       "      <td>45</td>\n",
       "      <td>ngay từ lúc đầu_tiên bước vào nhà_hàng đã được...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9067</th>\n",
       "      <td>9071</td>\n",
       "      <td>17</td>\n",
       "      <td>đặt ăn thử mà thấy ngón cá emo rất mê sẽ còn ủ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>9072</td>\n",
       "      <td>127</td>\n",
       "      <td>nay xem bóng_đá vn lười nấu cơm nghe các bạn g...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9069 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  len                                            Comment  \\\n",
       "0              0   13  xôi dẻo đồ_ăn đậm vị hộp xôi được lót lá trông...   \n",
       "1              1   53  gọi ship 1 xuất cari gà bánh naan và 3 miếng g...   \n",
       "2              2   48  thời_tiết lạnh như này cả nhà rủ nhau đến lega...   \n",
       "3              3   59  em có đọc review thấy mng bảo trà sữa nướng đề...   \n",
       "4              4   93  đồ_ăn rất ngon nhà_hàng cũng rất đẹp tất_cả đề...   \n",
       "...          ...  ...                                                ...   \n",
       "9064        9068   30  thực_sự mà nói thấy mọi người đánh_giá nhiều q...   \n",
       "9065        9069  134  lẩu thái tômyum đc 19 lò_đúc hbt hn theo đánh_...   \n",
       "9066        9070   45  ngay từ lúc đầu_tiên bước vào nhà_hàng đã được...   \n",
       "9067        9071   17  đặt ăn thử mà thấy ngón cá emo rất mê sẽ còn ủ...   \n",
       "9068        9072  127  nay xem bóng_đá vn lười nấu cơm nghe các bạn g...   \n",
       "\n",
       "      Rating  \n",
       "0        1.0  \n",
       "1        0.0  \n",
       "2        1.0  \n",
       "3        0.0  \n",
       "4        1.0  \n",
       "...      ...  \n",
       "9064     1.0  \n",
       "9065     1.0  \n",
       "9066     1.0  \n",
       "9067     1.0  \n",
       "9068     1.0  \n",
       "\n",
       "[9069 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4f1292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.060655Z",
     "iopub.status.busy": "2022-12-12T17:31:51.059783Z",
     "iopub.status.idle": "2022-12-12T17:31:51.064195Z",
     "shell.execute_reply": "2022-12-12T17:31:51.063381Z"
    },
    "papermill": {
     "duration": 0.024875,
     "end_time": "2022-12-12T17:31:51.066126",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.041251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = df[['RevId','Comment','label','Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af149cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.102601Z",
     "iopub.status.busy": "2022-12-12T17:31:51.102311Z",
     "iopub.status.idle": "2022-12-12T17:31:51.115709Z",
     "shell.execute_reply": "2022-12-12T17:31:51.114726Z"
    },
    "papermill": {
     "duration": 0.034473,
     "end_time": "2022-12-12T17:31:51.117804",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.083331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9069\n",
       "Name: Comment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Comment'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9890ae5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.156104Z",
     "iopub.status.busy": "2022-12-12T17:31:51.155259Z",
     "iopub.status.idle": "2022-12-12T17:31:51.159599Z",
     "shell.execute_reply": "2022-12-12T17:31:51.158727Z"
    },
    "papermill": {
     "duration": 0.025476,
     "end_time": "2022-12-12T17:31:51.161581",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.136105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b05ff8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.199228Z",
     "iopub.status.busy": "2022-12-12T17:31:51.198389Z",
     "iopub.status.idle": "2022-12-12T17:31:51.202962Z",
     "shell.execute_reply": "2022-12-12T17:31:51.202119Z"
    },
    "papermill": {
     "duration": 0.025288,
     "end_time": "2022-12-12T17:31:51.204920",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.179632",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_len = df['len'].to_list()\n",
    "# list_text = df['Comment'].to_list()\n",
    "# list_label = df['label'].to_list()\n",
    "\n",
    "# for i in range(len(list_len)):\n",
    "#     if list_len[i] >= 256:\n",
    "#         print(list_text[i])\n",
    "#         tmp = list_text[i].split()\n",
    "#         list_text[i] =  ' '.join(tmp[0:210]) + ' ' + ' '.join(tmp[-46:])\n",
    "#         print()\n",
    "#         print(list_text[i])\n",
    "#         print(list_label[i])\n",
    "#         print(\"hihihi\")\n",
    "\n",
    "# df['Comment'] = list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecaa322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.241751Z",
     "iopub.status.busy": "2022-12-12T17:31:51.241014Z",
     "iopub.status.idle": "2022-12-12T17:31:51.254496Z",
     "shell.execute_reply": "2022-12-12T17:31:51.253556Z"
    },
    "papermill": {
     "duration": 0.034314,
     "end_time": "2022-12-12T17:31:51.256438",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.222124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9069, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dd21a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.292990Z",
     "iopub.status.busy": "2022-12-12T17:31:51.292190Z",
     "iopub.status.idle": "2022-12-12T17:31:51.297383Z",
     "shell.execute_reply": "2022-12-12T17:31:51.296506Z"
    },
    "papermill": {
     "duration": 0.025481,
     "end_time": "2022-12-12T17:31:51.299380",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.273899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb91ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:51.337024Z",
     "iopub.status.busy": "2022-12-12T17:31:51.336187Z",
     "iopub.status.idle": "2022-12-12T17:31:52.338833Z",
     "shell.execute_reply": "2022-12-12T17:31:52.337735Z"
    },
    "papermill": {
     "duration": 1.023509,
     "end_time": "2022-12-12T17:31:52.341303",
     "exception": false,
     "start_time": "2022-12-12T17:31:51.317794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8069, 4), (1000, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=1000, random_state=42)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0e5c7d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:52.379598Z",
     "iopub.status.busy": "2022-12-12T17:31:52.378021Z",
     "iopub.status.idle": "2022-12-12T17:31:52.394069Z",
     "shell.execute_reply": "2022-12-12T17:31:52.392897Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036957,
     "end_time": "2022-12-12T17:31:52.396215",
     "exception": false,
     "start_time": "2022-12-12T17:31:52.359258",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6354, 4) (1715, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_train_x = df_train[df_train['Rating'] == 1]\n",
    "df_train_y = df_train[df_train['Rating'] == 0]\n",
    "print(df_train_x.shape, df_train_y.shape)\n",
    "df_train_x = df_train_x.sample(5500)\n",
    "df_train_y= df_train_y.sample(1000)\n",
    "\n",
    "df_train = pd.concat([df_train_x, df_train[df_train['Rating'] == 0], df_train_y],axis = 0)\n",
    "\n",
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3a00fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:52.433044Z",
     "iopub.status.busy": "2022-12-12T17:31:52.432775Z",
     "iopub.status.idle": "2022-12-12T17:31:52.436862Z",
     "shell.execute_reply": "2022-12-12T17:31:52.435820Z"
    },
    "papermill": {
     "duration": 0.024559,
     "end_time": "2022-12-12T17:31:52.438772",
     "exception": false,
     "start_time": "2022-12-12T17:31:52.414213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test = df_test[['Comment','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c671f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:52.475097Z",
     "iopub.status.busy": "2022-12-12T17:31:52.474844Z",
     "iopub.status.idle": "2022-12-12T17:31:52.483599Z",
     "shell.execute_reply": "2022-12-12T17:31:52.482657Z"
    },
    "papermill": {
     "duration": 0.029108,
     "end_time": "2022-12-12T17:31:52.485720",
     "exception": false,
     "start_time": "2022-12-12T17:31:52.456612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5500\n",
       "0    2715\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df50da1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:31:52.523074Z",
     "iopub.status.busy": "2022-12-12T17:31:52.522812Z",
     "iopub.status.idle": "2022-12-12T17:32:01.782646Z",
     "shell.execute_reply": "2022-12-12T17:32:01.781576Z"
    },
    "papermill": {
     "duration": 9.281792,
     "end_time": "2022-12-12T17:32:01.785317",
     "exception": false,
     "start_time": "2022-12-12T17:31:52.503525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras import regularizers, constraints\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de1c9ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:01.822711Z",
     "iopub.status.busy": "2022-12-12T17:32:01.822390Z",
     "iopub.status.idle": "2022-12-12T17:32:01.829169Z",
     "shell.execute_reply": "2022-12-12T17:32:01.828344Z"
    },
    "papermill": {
     "duration": 0.02739,
     "end_time": "2022-12-12T17:32:01.831143",
     "exception": false,
     "start_time": "2022-12-12T17:32:01.803753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172a1323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:01.868495Z",
     "iopub.status.busy": "2022-12-12T17:32:01.867614Z",
     "iopub.status.idle": "2022-12-12T17:32:01.940292Z",
     "shell.execute_reply": "2022-12-12T17:32:01.939172Z"
    },
    "papermill": {
     "duration": 0.09418,
     "end_time": "2022-12-12T17:32:01.943053",
     "exception": false,
     "start_time": "2022-12-12T17:32:01.848873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def load_bert():\n",
    "    v_phobert = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)\n",
    "    v_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "    return v_phobert, v_tokenizer\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d123b2ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:01.982301Z",
     "iopub.status.busy": "2022-12-12T17:32:01.981440Z",
     "iopub.status.idle": "2022-12-12T17:32:27.301340Z",
     "shell.execute_reply": "2022-12-12T17:32:27.300186Z"
    },
    "papermill": {
     "duration": 25.34135,
     "end_time": "2022-12-12T17:32:27.303637",
     "exception": false,
     "start_time": "2022-12-12T17:32:01.962287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9955f51de8b34e89af1476a6d92d2612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c735b8cfe8e46aca88e03ca42fdb575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/518M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bd80ca58064f3eb9fd4da4f9a5d241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f1be54aad140dd95e5207f53e5a4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "v_phobert = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)\n",
    "v_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16da496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.343754Z",
     "iopub.status.busy": "2022-12-12T17:32:27.342775Z",
     "iopub.status.idle": "2022-12-12T17:32:27.347901Z",
     "shell.execute_reply": "2022-12-12T17:32:27.346900Z"
    },
    "papermill": {
     "duration": 0.026897,
     "end_time": "2022-12-12T17:32:27.349802",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.322905",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v_phobert.embeddings.position_embeddings = nn.Embedding(1024, 768, padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0c0fb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.388548Z",
     "iopub.status.busy": "2022-12-12T17:32:27.387727Z",
     "iopub.status.idle": "2022-12-12T17:32:27.396478Z",
     "shell.execute_reply": "2022-12-12T17:32:27.395656Z"
    },
    "papermill": {
     "duration": 0.030018,
     "end_time": "2022-12-12T17:32:27.398418",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.368400",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_phobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5cecc3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.438323Z",
     "iopub.status.busy": "2022-12-12T17:32:27.437481Z",
     "iopub.status.idle": "2022-12-12T17:32:27.443625Z",
     "shell.execute_reply": "2022-12-12T17:32:27.442659Z"
    },
    "papermill": {
     "duration": 0.027845,
     "end_time": "2022-12-12T17:32:27.445667",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.417822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='vinai/phobert-base', vocab_size=64000, model_max_len=256, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3697bbfe",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.485211Z",
     "iopub.status.busy": "2022-12-12T17:32:27.484409Z",
     "iopub.status.idle": "2022-12-12T17:32:27.491595Z",
     "shell.execute_reply": "2022-12-12T17:32:27.490383Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02914,
     "end_time": "2022-12-12T17:32:27.493605",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.464465",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD phoBERT DONE\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 256\n",
    "print(\"LOAD phoBERT DONE\")\n",
    "\n",
    "def get_emb_vector(input_ids):\n",
    "    input_ids  = torch.tensor([input_ids]).to(torch.long)\n",
    "    with torch.no_grad():\n",
    "        features = phobert(input_ids.to(torch.device(\"cuda:0\")))\n",
    "    #print(features)\n",
    "    emb_vecs = features[0].cpu().numpy()[0]#[1:-1]\n",
    "    #print(emb_vecs)\n",
    "    return emb_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f1303e2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.534130Z",
     "iopub.status.busy": "2022-12-12T17:32:27.533272Z",
     "iopub.status.idle": "2022-12-12T17:32:27.538033Z",
     "shell.execute_reply": "2022-12-12T17:32:27.537210Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026821,
     "end_time": "2022-12-12T17:32:27.539931",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.513110",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text2ids(text):\n",
    "    # print(tokenizer.encode(\"<pad> nhà <pad>\"))\n",
    "    tkz = tokenizer.encode(text)\n",
    "    return tkz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bca6b8",
   "metadata": {
    "papermill": {
     "duration": 0.01871,
     "end_time": "2022-12-12T17:32:27.577652",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.558942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb9ab8b8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.617389Z",
     "iopub.status.busy": "2022-12-12T17:32:27.616544Z",
     "iopub.status.idle": "2022-12-12T17:32:27.629219Z",
     "shell.execute_reply": "2022-12-12T17:32:27.628384Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034352,
     "end_time": "2022-12-12T17:32:27.631162",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.596810",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, ids, labels, batch_size=16,  max_seq_len=256, feature_len=768, n_classes=18, shuffle=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.feature_len = feature_len\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, idx_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.max_seq_len, self.feature_len))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        # Generate data\n",
    "        for i, idx in enumerate(idx_temp):\n",
    "            X[i,] = get_emb_vector(self.ids[idx])\n",
    "            # Store class\n",
    "            y[i] = self.labels[idx]\n",
    "        # X = X[:,:,:,np.newaxis]\n",
    "        # y = to_categorical(y, num_classes=self.n_classes)\n",
    "        # print(y.shape)\n",
    "        # exit()\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42f588dd",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.671112Z",
     "iopub.status.busy": "2022-12-12T17:32:27.670259Z",
     "iopub.status.idle": "2022-12-12T17:32:27.674674Z",
     "shell.execute_reply": "2022-12-12T17:32:27.673691Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026368,
     "end_time": "2022-12-12T17:32:27.676574",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.650206",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_generator = DataGenerator(ids_train, y_train, batch_size=8, n_classes=len(classes))\n",
    "# valid_generator = DataGenerator(ids_test, y_test, batch_size=8, n_classes=len(classes), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35545f31",
   "metadata": {
    "papermill": {
     "duration": 0.020118,
     "end_time": "2022-12-12T17:32:27.717233",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.697115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d80fa72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.758227Z",
     "iopub.status.busy": "2022-12-12T17:32:27.757631Z",
     "iopub.status.idle": "2022-12-12T17:32:27.761843Z",
     "shell.execute_reply": "2022-12-12T17:32:27.760932Z"
    },
    "papermill": {
     "duration": 0.026607,
     "end_time": "2022-12-12T17:32:27.763805",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.737198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def standardize_data(row):\n",
    "#     # Xóa dấu chấm, phẩy, hỏi ở cuối câu\n",
    "#     row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
    "#     # Xóa tất cả dấu chấm, phẩy, chấm phẩy, chấm thang, ... trong câu\n",
    "#     row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
    "#         .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "#         .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "#         .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "#         .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "#         .replace(\"-\", \" \").replace(\"?\", \" \")\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a95d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.803570Z",
     "iopub.status.busy": "2022-12-12T17:32:27.802754Z",
     "iopub.status.idle": "2022-12-12T17:32:27.817311Z",
     "shell.execute_reply": "2022-12-12T17:32:27.816510Z"
    },
    "papermill": {
     "duration": 0.036418,
     "end_time": "2022-12-12T17:32:27.819227",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.782809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Bert_fine_tuning(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_fine_tuning, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=768, out_features = 500, bias=True).to(device),\n",
    "            nn.BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True).to(device),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(in_features=500, out_features = 2, bias=True).to(device)\n",
    "        )\n",
    "        self.criterior = nn.CrossEntropyLoss()\n",
    "        # self.criterior = nn.BCEWithLogitsLoss()\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        param_optimizer = list(self.bert.named_parameters())\n",
    "        self.optimizer =optim.AdamW(\n",
    "#             [{'params': self.bert.parameters(), 'lr': 8e-5}, \n",
    "#             {'params': self.classifier.parameters(), 'lr': 1e-3}],\n",
    "            [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "            {'params': self.classifier.parameters(), 'lr': 1e-3}],\n",
    "            lr = 2e-5\n",
    "#              momentum=0.9\n",
    "        )\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    \n",
    "    def tokenize(self,v_text, label):\n",
    "        v_tokenized = []\n",
    "        max_len = 256 \n",
    "        for i_text in v_text:\n",
    "#             i_text = standardize_data(i_text)\n",
    "            line = self.tokenizer.encode(i_text, max_length = 256)\n",
    "            v_tokenized.append(line)\n",
    "\n",
    "        padded = numpy.array([i + [1] * (max_len - len(i)) for i in v_tokenized])\n",
    "        print('padded:', padded[0])\n",
    "        print('len padded:', padded.shape)\n",
    "        attention_mask = numpy.where(padded == 1, 0, 1)\n",
    "        print('attention mask:', attention_mask[0])\n",
    "        padded = torch.tensor(padded).to(torch.long)\n",
    "        print(\"Padd = \",padded.size())\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "        \n",
    "        target = torch.tensor(label) \n",
    "        print(target)\n",
    "        data_tensor = TensorDataset(padded, target) \n",
    "        train_loader = DataLoader(dataset = data_tensor, batch_size = 10)\n",
    "        attention_mask = DataLoader(attention_mask, batch_size = 10)\n",
    "        \n",
    "        return train_loader, attention_mask\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "             return_dict=False\n",
    "        )\n",
    "#         self.drop = nn.Dropout(p=0.2)\n",
    "#         output = self.drop(pooled_output)\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    "#         return self.sigmoid(output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c9f93df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.858806Z",
     "iopub.status.busy": "2022-12-12T17:32:27.858534Z",
     "iopub.status.idle": "2022-12-12T17:32:27.870873Z",
     "shell.execute_reply": "2022-12-12T17:32:27.870026Z"
    },
    "papermill": {
     "duration": 0.034477,
     "end_time": "2022-12-12T17:32:27.872783",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.838306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train_model(bert, save_path, df_train, df_val, num_epochs=1):\n",
    "        text_train = df_train['Comment'].to_list()\n",
    "        label_train = df_train['Rating'].to_list()\n",
    "        text_test = df_test['Comment'].to_list()\n",
    "        label_test = df_test['Rating'].to_list()\n",
    "        \n",
    "        Data_train, attention_train = bert.tokenize(text_train, label_train)\n",
    "        Data_test, attention_test = bert.tokenize(text_test, label_test)\n",
    "        \n",
    "        dataloader_dict = {\n",
    "            'train' : Data_train,\n",
    "            'test' : Data_test\n",
    "        }\n",
    "\n",
    "        list_tmp = []\n",
    "        \n",
    "        for epoch in range(num_epochs + 1):\n",
    "            if epoch == 0:\n",
    "                print()\n",
    "                continue\n",
    "            print(\"Epoch {}/{} \".format(epoch, num_epochs))\n",
    "\n",
    "            for phase in ['train', 'test']:\n",
    "                if phase == 'train':\n",
    "                    bert.train()\n",
    "                    attention = attention_train\n",
    "                else:\n",
    "                    bert.eval()\n",
    "                    attention = attention_test\n",
    "\n",
    "                epoch_loss = 0.0\n",
    "                epoch_corrects = 0\n",
    "\n",
    "                for (inputs, labels), i_attention in tqdm(zip(dataloader_dict[phase], attention)):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    i_attention = i_attention.to(device)\n",
    "\n",
    "                    bert.optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = bert(inputs,i_attention)\n",
    "\n",
    "                        loss = bert.criterior(outputs, labels)\n",
    "\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            bert.optimizer.step()\n",
    "\n",
    "                        epoch_loss += loss.item() * inputs.size(0)\n",
    "                        epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                    # with torch.no_grad():\n",
    "                    #     outputs = bert(inputs, i_attention)\n",
    "                    #     loss = bert.criterior(outputs, labels)\n",
    "                    #\n",
    "                    #     list_tmp.append(outputs)\n",
    "                    #     print(outputs)\n",
    "                    #\n",
    "                    #     _, preds = torch.max(outputs, 1)\n",
    "                    #\n",
    "                    #     del outputs\n",
    "                    #     torch.cuda.empty_cache()\n",
    "                    #     gc.collect()\n",
    "                    #\n",
    "                    #     if phase == 'train':\n",
    "                    #         loss.backward()\n",
    "                    #         bert.optimizer.step()\n",
    "                    #\n",
    "                    #     epoch_loss += loss.item() * inputs.size(0)\n",
    "                    #     epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "                epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "                epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "\n",
    "                print(\"{} Loss: {:.4f}  Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "                torch.save(bert.bert.state_dict(), \"./bert_model{}.pth\".format(epoch))\n",
    "                torch.save(bert.state_dict(), \"./full_bert_model{}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e73d2bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.913259Z",
     "iopub.status.busy": "2022-12-12T17:32:27.912986Z",
     "iopub.status.idle": "2022-12-12T17:32:27.916985Z",
     "shell.execute_reply": "2022-12-12T17:32:27.915978Z"
    },
    "papermill": {
     "duration": 0.026159,
     "end_time": "2022-12-12T17:32:27.918892",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.892733",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "687cfdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:32:27.958676Z",
     "iopub.status.busy": "2022-12-12T17:32:27.957837Z",
     "iopub.status.idle": "2022-12-12T17:53:25.441420Z",
     "shell.execute_reply": "2022-12-12T17:53:25.439882Z"
    },
    "papermill": {
     "duration": 1257.508376,
     "end_time": "2022-12-12T17:53:25.446135",
     "exception": false,
     "start_time": "2022-12-12T17:32:27.937759",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [   0 1157 3589  164  133  123  390 7784  281 2273    2    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1]\n",
      "len padded: (8215, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([8215, 256])\n",
      "tensor([1, 1, 1,  ..., 0, 1, 1])\n",
      "padded: [    0  4036   364  2977 13740    51  3585    17  1019  1325   246    15\n",
      "   133   123 15370  2263   889  3619  1947    95  2607    51   203  5634\n",
      "    17  2023   566 19505   889 10831  1947    95  2607    51    74    24\n",
      "   137    76   107   566 19505   308     6    17  1834 12291  4481  1917\n",
      "  1947    95    73    54  1236  6625  2008  8813     6    17  1019  1834\n",
      "  1695    14  8861  2114   437    73  1834    68 49833  3030  2857  2537\n",
      "     6  2122  4407    51   139  1498   131    17  1026 16767     7   946\n",
      "  2621   234    51  2475    15  3538    54    44    17   549  2169     8\n",
      "   281  2804    90   523 37973   167    28   946    36  3787  1595  1521\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "len padded: (1000, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([1000, 256])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n",
      "\n",
      "Epoch 1/5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [03:56,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3377  Acc: 0.8795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2701  Acc: 0.8930\n",
      "Epoch 2/5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [03:55,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2646  Acc: 0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2889  Acc: 0.9210\n",
      "Epoch 3/5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [03:55,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1890  Acc: 0.9351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3146  Acc: 0.9080\n",
      "Epoch 4/5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [03:55,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1466  Acc: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2678  Acc: 0.9090\n",
      "Epoch 5/5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "822it [03:55,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1123  Acc: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2655  Acc: 0.9180\n"
     ]
    }
   ],
   "source": [
    "# from pytorch_pretrained_bert.optimization import BertAdam\n",
    "\n",
    "b =  Bert_fine_tuning()\n",
    "train_model(b,\"./\", df_train, df_test, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c335a90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:25.983116Z",
     "iopub.status.busy": "2022-12-12T17:53:25.982758Z",
     "iopub.status.idle": "2022-12-12T17:53:41.287891Z",
     "shell.execute_reply": "2022-12-12T17:53:41.286757Z"
    },
    "papermill": {
     "duration": 15.541853,
     "end_time": "2022-12-12T17:53:41.290356",
     "exception": false,
     "start_time": "2022-12-12T17:53:25.748503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Bert_fine_tuning()\n",
    "w = torch.load('full_bert_model1.pth')\n",
    "b.load_state_dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2883b",
   "metadata": {
    "papermill": {
     "duration": 0.236583,
     "end_time": "2022-12-12T17:53:41.760881",
     "exception": false,
     "start_time": "2022-12-12T17:53:41.524298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c81f479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:42.226553Z",
     "iopub.status.busy": "2022-12-12T17:53:42.226196Z",
     "iopub.status.idle": "2022-12-12T17:53:51.991172Z",
     "shell.execute_reply": "2022-12-12T17:53:51.989818Z"
    },
    "papermill": {
     "duration": 10.002203,
     "end_time": "2022-12-12T17:53:51.994516",
     "exception": false,
     "start_time": "2022-12-12T17:53:41.992313",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [    0  4036   364  2977 13740    51  3585    17  1019  1325   246    15\n",
      "   133   123 15370  2263   889  3619  1947    95  2607    51   203  5634\n",
      "    17  2023   566 19505   889 10831  1947    95  2607    51    74    24\n",
      "   137    76   107   566 19505   308     6    17  1834 12291  4481  1917\n",
      "  1947    95    73    54  1236  6625  2008  8813     6    17  1019  1834\n",
      "  1695    14  8861  2114   437    73  1834    68 49833  3030  2857  2537\n",
      "     6  2122  4407    51   139  1498   131    17  1026 16767     7   946\n",
      "  2621   234    51  2475    15  3538    54    44    17   549  2169     8\n",
      "   281  2804    90   523 37973   167    28   946    36  3787  1595  1521\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "len padded: (1000, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([1000, 256])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.2701  Acc: 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "\n",
    "text_test = df_test['Comment'].to_list()\n",
    "label_test = df_test['Rating'].to_list()\n",
    "\n",
    "epoch_loss = 0.0\n",
    "epoch_corrects = 0\n",
    "net = b\n",
    "net.eval()\n",
    "Data_test, attention_test = b.tokenize(text_test, label_test)\n",
    "attention = attention_test\n",
    "\n",
    "list_pred = np.array([])\n",
    "            \n",
    "for (inputs, labels), i_attention in tqdm(zip(Data_test, attention)):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    i_attention = i_attention.to(device)\n",
    "    \n",
    "    outputs = b(inputs,i_attention)\n",
    "        \n",
    "    loss = b.criterior(outputs,labels)      \n",
    "        \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "#     print(preds.cpu().numpy())\n",
    "    list_pred = np.append(list_pred,preds.cpu().numpy())\n",
    "        \n",
    "    epoch_loss += loss.item() * inputs.size(0)\n",
    "    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "epoch_loss = epoch_loss / len(Data_test.dataset)\n",
    "epoch_acc = epoch_corrects.double() / len(Data_test.dataset)\n",
    "            \n",
    "print(\" Loss: {:.4f}  Acc: {:.4f}\".format( epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d78e1e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:52.535109Z",
     "iopub.status.busy": "2022-12-12T17:53:52.534727Z",
     "iopub.status.idle": "2022-12-12T17:53:52.539098Z",
     "shell.execute_reply": "2022-12-12T17:53:52.538104Z"
    },
    "papermill": {
     "duration": 0.242504,
     "end_time": "2022-12-12T17:53:52.541233",
     "exception": false,
     "start_time": "2022-12-12T17:53:52.298729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(b.bert.state_dict(),\"./bert_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f76ede27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:53.008902Z",
     "iopub.status.busy": "2022-12-12T17:53:53.008523Z",
     "iopub.status.idle": "2022-12-12T17:53:53.021971Z",
     "shell.execute_reply": "2022-12-12T17:53:53.020811Z"
    },
    "papermill": {
     "duration": 0.249841,
     "end_time": "2022-12-12T17:53:53.024534",
     "exception": false,
     "start_time": "2022-12-12T17:53:52.774693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Accuracy Score ->  89.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78       204\n",
      "           1       0.98      0.89      0.93       796\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.83      0.90      0.85      1000\n",
      "weighted avg       0.91      0.89      0.90      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list_pred\n",
    "\n",
    "print(\"BERT Accuracy Score -> \",accuracy_score(list_pred, label_test)*100)\n",
    "\n",
    "print(classification_report(label_test,list_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6488b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:53.539532Z",
     "iopub.status.busy": "2022-12-12T17:53:53.539171Z",
     "iopub.status.idle": "2022-12-12T17:53:53.543674Z",
     "shell.execute_reply": "2022-12-12T17:53:53.542764Z"
    },
    "papermill": {
     "duration": 0.285735,
     "end_time": "2022-12-12T17:53:53.545654",
     "exception": false,
     "start_time": "2022-12-12T17:53:53.259919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check 1\n",
    "\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "# ]\n",
    "# num_train_optimization_steps = int(args.epochs*len(train_df)/args.batch_size/args.accumulation_steps)\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b520dce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:54.024336Z",
     "iopub.status.busy": "2022-12-12T17:53:54.023986Z",
     "iopub.status.idle": "2022-12-12T17:53:54.043449Z",
     "shell.execute_reply": "2022-12-12T17:53:54.042494Z"
    },
    "papermill": {
     "duration": 0.257156,
     "end_time": "2022-12-12T17:53:54.045502",
     "exception": false,
     "start_time": "2022-12-12T17:53:53.788346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attention Layer\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9780e9",
   "metadata": {
    "papermill": {
     "duration": 0.23481,
     "end_time": "2022-12-12T17:53:54.515111",
     "exception": false,
     "start_time": "2022-12-12T17:53:54.280301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## combine with tree-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c436a",
   "metadata": {
    "papermill": {
     "duration": 0.234163,
     "end_time": "2022-12-12T17:53:54.982125",
     "exception": false,
     "start_time": "2022-12-12T17:53:54.747962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c09644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:55.500277Z",
     "iopub.status.busy": "2022-12-12T17:53:55.498499Z",
     "iopub.status.idle": "2022-12-12T17:53:55.509531Z",
     "shell.execute_reply": "2022-12-12T17:53:55.508720Z"
    },
    "papermill": {
     "duration": 0.2501,
     "end_time": "2022-12-12T17:53:55.511453",
     "exception": false,
     "start_time": "2022-12-12T17:53:55.261353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_bert_features(v_text):\n",
    "    global phobert, sw\n",
    "    v_tokenized = []\n",
    "    \n",
    "    max_len = 256 \n",
    "    for i_text in v_text:\n",
    "#         i_text = standardize_data(i_text)\n",
    "        line = tokenizer.encode(i_text, max_length = 256)\n",
    "        v_tokenized.append(line)\n",
    "\n",
    "    \n",
    "    # Chèn thêm số 1 vào cuối câu nếu như không đủ 256 từ\n",
    "    padded = numpy.array([i + [1] * (max_len - len(i)) for i in v_tokenized])\n",
    "    print('padded:', padded[0])\n",
    "    print('len padded:', padded.shape)\n",
    "\n",
    "    # Đánh dấu các từ thêm vào = 0 để không tính vào quá trình lấy features\n",
    "    attention_mask = numpy.where(padded == 1, 0, 1)\n",
    "    print('attention mask:', attention_mask[0])\n",
    "\n",
    "    padded = torch.tensor(padded).to(torch.long)\n",
    "    print(\"Padd = \",padded.size())\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    \n",
    "    padded = DataLoader(padded, batch_size=32)\n",
    "    attention_mask = DataLoader(attention_mask, batch_size = 32)\n",
    "    check = False\n",
    "    v_feats = None\n",
    "    for data, i_mask in zip(padded, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = phobert(input_ids=data.to(device), attention_mask = i_mask.to(device))\n",
    "            v_features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
    "            if check is False: \n",
    "                v_feats = v_features\n",
    "                check = True\n",
    "            else:\n",
    "                v_feats = np.append(v_feats, v_features, axis = 0)\n",
    "                \n",
    "        print(v_feats.shape)\n",
    "                                    \n",
    "    print(v_feats.shape)\n",
    "    return v_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8a27b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:53:55.979494Z",
     "iopub.status.busy": "2022-12-12T17:53:55.979122Z",
     "iopub.status.idle": "2022-12-12T17:55:09.462827Z",
     "shell.execute_reply": "2022-12-12T17:55:09.461253Z"
    },
    "papermill": {
     "duration": 73.722807,
     "end_time": "2022-12-12T17:55:09.466067",
     "exception": false,
     "start_time": "2022-12-12T17:53:55.743260",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [   0 1157 3589  164  133  123  390 7784  281 2273    2    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1]\n",
      "len padded: (8215, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([8215, 256])\n",
      "(32, 768)\n",
      "(64, 768)\n",
      "(96, 768)\n",
      "(128, 768)\n",
      "(160, 768)\n",
      "(192, 768)\n",
      "(224, 768)\n",
      "(256, 768)\n",
      "(288, 768)\n",
      "(320, 768)\n",
      "(352, 768)\n",
      "(384, 768)\n",
      "(416, 768)\n",
      "(448, 768)\n",
      "(480, 768)\n",
      "(512, 768)\n",
      "(544, 768)\n",
      "(576, 768)\n",
      "(608, 768)\n",
      "(640, 768)\n",
      "(672, 768)\n",
      "(704, 768)\n",
      "(736, 768)\n",
      "(768, 768)\n",
      "(800, 768)\n",
      "(832, 768)\n",
      "(864, 768)\n",
      "(896, 768)\n",
      "(928, 768)\n",
      "(960, 768)\n",
      "(992, 768)\n",
      "(1024, 768)\n",
      "(1056, 768)\n",
      "(1088, 768)\n",
      "(1120, 768)\n",
      "(1152, 768)\n",
      "(1184, 768)\n",
      "(1216, 768)\n",
      "(1248, 768)\n",
      "(1280, 768)\n",
      "(1312, 768)\n",
      "(1344, 768)\n",
      "(1376, 768)\n",
      "(1408, 768)\n",
      "(1440, 768)\n",
      "(1472, 768)\n",
      "(1504, 768)\n",
      "(1536, 768)\n",
      "(1568, 768)\n",
      "(1600, 768)\n",
      "(1632, 768)\n",
      "(1664, 768)\n",
      "(1696, 768)\n",
      "(1728, 768)\n",
      "(1760, 768)\n",
      "(1792, 768)\n",
      "(1824, 768)\n",
      "(1856, 768)\n",
      "(1888, 768)\n",
      "(1920, 768)\n",
      "(1952, 768)\n",
      "(1984, 768)\n",
      "(2016, 768)\n",
      "(2048, 768)\n",
      "(2080, 768)\n",
      "(2112, 768)\n",
      "(2144, 768)\n",
      "(2176, 768)\n",
      "(2208, 768)\n",
      "(2240, 768)\n",
      "(2272, 768)\n",
      "(2304, 768)\n",
      "(2336, 768)\n",
      "(2368, 768)\n",
      "(2400, 768)\n",
      "(2432, 768)\n",
      "(2464, 768)\n",
      "(2496, 768)\n",
      "(2528, 768)\n",
      "(2560, 768)\n",
      "(2592, 768)\n",
      "(2624, 768)\n",
      "(2656, 768)\n",
      "(2688, 768)\n",
      "(2720, 768)\n",
      "(2752, 768)\n",
      "(2784, 768)\n",
      "(2816, 768)\n",
      "(2848, 768)\n",
      "(2880, 768)\n",
      "(2912, 768)\n",
      "(2944, 768)\n",
      "(2976, 768)\n",
      "(3008, 768)\n",
      "(3040, 768)\n",
      "(3072, 768)\n",
      "(3104, 768)\n",
      "(3136, 768)\n",
      "(3168, 768)\n",
      "(3200, 768)\n",
      "(3232, 768)\n",
      "(3264, 768)\n",
      "(3296, 768)\n",
      "(3328, 768)\n",
      "(3360, 768)\n",
      "(3392, 768)\n",
      "(3424, 768)\n",
      "(3456, 768)\n",
      "(3488, 768)\n",
      "(3520, 768)\n",
      "(3552, 768)\n",
      "(3584, 768)\n",
      "(3616, 768)\n",
      "(3648, 768)\n",
      "(3680, 768)\n",
      "(3712, 768)\n",
      "(3744, 768)\n",
      "(3776, 768)\n",
      "(3808, 768)\n",
      "(3840, 768)\n",
      "(3872, 768)\n",
      "(3904, 768)\n",
      "(3936, 768)\n",
      "(3968, 768)\n",
      "(4000, 768)\n",
      "(4032, 768)\n",
      "(4064, 768)\n",
      "(4096, 768)\n",
      "(4128, 768)\n",
      "(4160, 768)\n",
      "(4192, 768)\n",
      "(4224, 768)\n",
      "(4256, 768)\n",
      "(4288, 768)\n",
      "(4320, 768)\n",
      "(4352, 768)\n",
      "(4384, 768)\n",
      "(4416, 768)\n",
      "(4448, 768)\n",
      "(4480, 768)\n",
      "(4512, 768)\n",
      "(4544, 768)\n",
      "(4576, 768)\n",
      "(4608, 768)\n",
      "(4640, 768)\n",
      "(4672, 768)\n",
      "(4704, 768)\n",
      "(4736, 768)\n",
      "(4768, 768)\n",
      "(4800, 768)\n",
      "(4832, 768)\n",
      "(4864, 768)\n",
      "(4896, 768)\n",
      "(4928, 768)\n",
      "(4960, 768)\n",
      "(4992, 768)\n",
      "(5024, 768)\n",
      "(5056, 768)\n",
      "(5088, 768)\n",
      "(5120, 768)\n",
      "(5152, 768)\n",
      "(5184, 768)\n",
      "(5216, 768)\n",
      "(5248, 768)\n",
      "(5280, 768)\n",
      "(5312, 768)\n",
      "(5344, 768)\n",
      "(5376, 768)\n",
      "(5408, 768)\n",
      "(5440, 768)\n",
      "(5472, 768)\n",
      "(5504, 768)\n",
      "(5536, 768)\n",
      "(5568, 768)\n",
      "(5600, 768)\n",
      "(5632, 768)\n",
      "(5664, 768)\n",
      "(5696, 768)\n",
      "(5728, 768)\n",
      "(5760, 768)\n",
      "(5792, 768)\n",
      "(5824, 768)\n",
      "(5856, 768)\n",
      "(5888, 768)\n",
      "(5920, 768)\n",
      "(5952, 768)\n",
      "(5984, 768)\n",
      "(6016, 768)\n",
      "(6048, 768)\n",
      "(6080, 768)\n",
      "(6112, 768)\n",
      "(6144, 768)\n",
      "(6176, 768)\n",
      "(6208, 768)\n",
      "(6240, 768)\n",
      "(6272, 768)\n",
      "(6304, 768)\n",
      "(6336, 768)\n",
      "(6368, 768)\n",
      "(6400, 768)\n",
      "(6432, 768)\n",
      "(6464, 768)\n",
      "(6496, 768)\n",
      "(6528, 768)\n",
      "(6560, 768)\n",
      "(6592, 768)\n",
      "(6624, 768)\n",
      "(6656, 768)\n",
      "(6688, 768)\n",
      "(6720, 768)\n",
      "(6752, 768)\n",
      "(6784, 768)\n",
      "(6816, 768)\n",
      "(6848, 768)\n",
      "(6880, 768)\n",
      "(6912, 768)\n",
      "(6944, 768)\n",
      "(6976, 768)\n",
      "(7008, 768)\n",
      "(7040, 768)\n",
      "(7072, 768)\n",
      "(7104, 768)\n",
      "(7136, 768)\n",
      "(7168, 768)\n",
      "(7200, 768)\n",
      "(7232, 768)\n",
      "(7264, 768)\n",
      "(7296, 768)\n",
      "(7328, 768)\n",
      "(7360, 768)\n",
      "(7392, 768)\n",
      "(7424, 768)\n",
      "(7456, 768)\n",
      "(7488, 768)\n",
      "(7520, 768)\n",
      "(7552, 768)\n",
      "(7584, 768)\n",
      "(7616, 768)\n",
      "(7648, 768)\n",
      "(7680, 768)\n",
      "(7712, 768)\n",
      "(7744, 768)\n",
      "(7776, 768)\n",
      "(7808, 768)\n",
      "(7840, 768)\n",
      "(7872, 768)\n",
      "(7904, 768)\n",
      "(7936, 768)\n",
      "(7968, 768)\n",
      "(8000, 768)\n",
      "(8032, 768)\n",
      "(8064, 768)\n",
      "(8096, 768)\n",
      "(8128, 768)\n",
      "(8160, 768)\n",
      "(8192, 768)\n",
      "(8215, 768)\n",
      "(8215, 768)\n",
      "padded: [    0  4036   364  2977 13740    51  3585    17  1019  1325   246    15\n",
      "   133   123 15370  2263   889  3619  1947    95  2607    51   203  5634\n",
      "    17  2023   566 19505   889 10831  1947    95  2607    51    74    24\n",
      "   137    76   107   566 19505   308     6    17  1834 12291  4481  1917\n",
      "  1947    95    73    54  1236  6625  2008  8813     6    17  1019  1834\n",
      "  1695    14  8861  2114   437    73  1834    68 49833  3030  2857  2537\n",
      "     6  2122  4407    51   139  1498   131    17  1026 16767     7   946\n",
      "  2621   234    51  2475    15  3538    54    44    17   549  2169     8\n",
      "   281  2804    90   523 37973   167    28   946    36  3787  1595  1521\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "len padded: (1000, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([1000, 256])\n",
      "(32, 768)\n",
      "(64, 768)\n",
      "(96, 768)\n",
      "(128, 768)\n",
      "(160, 768)\n",
      "(192, 768)\n",
      "(224, 768)\n",
      "(256, 768)\n",
      "(288, 768)\n",
      "(320, 768)\n",
      "(352, 768)\n",
      "(384, 768)\n",
      "(416, 768)\n",
      "(448, 768)\n",
      "(480, 768)\n",
      "(512, 768)\n",
      "(544, 768)\n",
      "(576, 768)\n",
      "(608, 768)\n",
      "(640, 768)\n",
      "(672, 768)\n",
      "(704, 768)\n",
      "(736, 768)\n",
      "(768, 768)\n",
      "(800, 768)\n",
      "(832, 768)\n",
      "(864, 768)\n",
      "(896, 768)\n",
      "(928, 768)\n",
      "(960, 768)\n",
      "(992, 768)\n",
      "(1000, 768)\n",
      "(1000, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "tokenizer = v_tokenizer\n",
    "phobert = b.bert\n",
    "\n",
    "\n",
    "text_train = df_train['Comment'].to_list()\n",
    "label_train = df_train['Rating'].to_list()\n",
    "text_test = df_test['Comment'].to_list()\n",
    "label_test = df_test['Rating'].to_list()\n",
    "\n",
    "\n",
    "\n",
    "features_train = make_bert_features(text_train)\n",
    "features_test = make_bert_features(text_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18404b69",
   "metadata": {
    "papermill": {
     "duration": 0.252671,
     "end_time": "2022-12-12T17:55:10.035172",
     "exception": false,
     "start_time": "2022-12-12T17:55:09.782501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BERT Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a208277",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:10.535530Z",
     "iopub.status.busy": "2022-12-12T17:55:10.535160Z",
     "iopub.status.idle": "2022-12-12T17:55:10.540173Z",
     "shell.execute_reply": "2022-12-12T17:55:10.539250Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.257978,
     "end_time": "2022-12-12T17:55:10.542152",
     "exception": false,
     "start_time": "2022-12-12T17:55:10.284174",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_bert():\n",
    "#\n",
    "#     model = Sequential()\n",
    "#     model.add(embed)\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(768, use_bias=True))\n",
    "#     model.add(BatchNormalizationV1(500, epsilon=1e-5, momentum=0.1))\n",
    "#     model.add(ReLU())\n",
    "#     model.add(Dropout(0.1))\n",
    "#     model.add(Dense(500))\n",
    "#     #model.add(nn.Linear(in_features=768, out_features = 500, bias=True))\n",
    "#     # model.add(nn.BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True).to(device))\n",
    "#     # model.add(nn.ReLU(inplace=True))\n",
    "#     # model.add(nn.Dropout(p=0.1))\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.build(input_shape=(1,1,256,768))\n",
    "#     model.summary()\n",
    "#\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1367a47c",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:11.081790Z",
     "iopub.status.busy": "2022-12-12T17:55:11.081402Z",
     "iopub.status.idle": "2022-12-12T17:55:11.086072Z",
     "shell.execute_reply": "2022-12-12T17:55:11.085090Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.30006,
     "end_time": "2022-12-12T17:55:11.087997",
     "exception": false,
     "start_time": "2022-12-12T17:55:10.787937",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert = create_bert()\n",
    "# bert.built()\n",
    "# bert.fit(features_train, np.array(label_train))\n",
    "# predictions_bert = bert.predict(features_test)\n",
    "#\n",
    "# print(\"BERT Accuracy Score -> \",accuracy_score(predictions_bert, label_test)*100)\n",
    "# print(classification_report(label_test,predictions_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d620cb9",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:11.594749Z",
     "iopub.status.busy": "2022-12-12T17:55:11.594370Z",
     "iopub.status.idle": "2022-12-12T17:55:11.599122Z",
     "shell.execute_reply": "2022-12-12T17:55:11.598147Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.266587,
     "end_time": "2022-12-12T17:55:11.601197",
     "exception": false,
     "start_time": "2022-12-12T17:55:11.334610",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "#\n",
    "# step_factor = 0.02\n",
    "# threshold_value = 0.2\n",
    "# roc_score=0\n",
    "# predicted_proba = bert.predict_proba(features_test) #probability of prediction\n",
    "# while threshold_value <=0.9: #continue to check best threshold upto probability 0.8\n",
    "#     temp_thresh = threshold_value\n",
    "#     predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "#     print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "#     if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "#         roc_score = roc_auc_score(label_test, predicted)\n",
    "#         thrsh_score = threshold_value\n",
    "#     threshold_value = threshold_value + step_factor\n",
    "# print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35edb87c",
   "metadata": {
    "papermill": {
     "duration": 0.249324,
     "end_time": "2022-12-12T17:55:12.100297",
     "exception": false,
     "start_time": "2022-12-12T17:55:11.850973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LIGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6112c5b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:12.649305Z",
     "iopub.status.busy": "2022-12-12T17:55:12.648942Z",
     "iopub.status.idle": "2022-12-12T17:55:30.514361Z",
     "shell.execute_reply": "2022-12-12T17:55:30.511768Z"
    },
    "papermill": {
     "duration": 18.120268,
     "end_time": "2022-12-12T17:55:30.517397",
     "exception": false,
     "start_time": "2022-12-12T17:55:12.397129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligbm Accuracy Score ->  94.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       204\n",
      "           1       0.96      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.92      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "train = lgbm.fit(features_train,label_train)\n",
    "predictions_lgbm = lgbm.predict(features_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"ligbm Accuracy Score -> \",accuracy_score(predictions_lgbm, label_test)*100)\n",
    "print(classification_report(label_test,predictions_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20c76839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:31.262514Z",
     "iopub.status.busy": "2022-12-12T17:55:31.261632Z",
     "iopub.status.idle": "2022-12-12T17:55:31.281342Z",
     "shell.execute_reply": "2022-12-12T17:55:31.280312Z"
    },
    "papermill": {
     "duration": 0.326836,
     "end_time": "2022-12-12T17:55:31.283589",
     "exception": false,
     "start_time": "2022-12-12T17:55:30.956753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "predictions_lgbm = (lgbm.predict_proba(features_test)[:,1] >= 0.5).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a6d2480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:31.832528Z",
     "iopub.status.busy": "2022-12-12T17:55:31.832153Z",
     "iopub.status.idle": "2022-12-12T17:55:31.850844Z",
     "shell.execute_reply": "2022-12-12T17:55:31.849657Z"
    },
    "papermill": {
     "duration": 0.322081,
     "end_time": "2022-12-12T17:55:31.853486",
     "exception": false,
     "start_time": "2022-12-12T17:55:31.531405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligbm Accuracy Score ->  94.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       204\n",
      "           1       0.96      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.92      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n",
      "0.8973174697014484\n"
     ]
    }
   ],
   "source": [
    "print(\"ligbm Accuracy Score -> \",accuracy_score(predictions_lgbm, label_test)*100)\n",
    "print(classification_report(label_test,predictions_lgbm))\n",
    "print(roc_auc_score(label_test, predictions_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4f071d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:32.353736Z",
     "iopub.status.busy": "2022-12-12T17:55:32.352728Z",
     "iopub.status.idle": "2022-12-12T17:55:32.357703Z",
     "shell.execute_reply": "2022-12-12T17:55:32.356758Z"
    },
    "papermill": {
     "duration": 0.256309,
     "end_time": "2022-12-12T17:55:32.359634",
     "exception": false,
     "start_time": "2022-12-12T17:55:32.103325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# # boosting_type = 'goss', learning_rate = 0.05, n_estimators = 200,num_leaves = 20, scale_pos_weight = 0.7\n",
    "# classifier = BalancedBaggingClassifier(base_estimator=LGBMClassifier(),\n",
    "#                                 sampling_strategy='not majority',\n",
    "#                                 replacement=False,\n",
    "#                                 random_state=42)\n",
    "\n",
    "# classifier.fit(features_train,label_train)\n",
    "# predictions_bag = classifier.predict(features_test)\n",
    "# # Use accuracy_score function to get the accuracy\n",
    "# print(\"ligbm Accuracy Score -> \",accuracy_score(predictions_bag, label_test)*100)\n",
    "# print(classification_report(label_test,predictions_bag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dc159c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:32.868668Z",
     "iopub.status.busy": "2022-12-12T17:55:32.868312Z",
     "iopub.status.idle": "2022-12-12T17:55:32.984363Z",
     "shell.execute_reply": "2022-12-12T17:55:32.982761Z"
    },
    "papermill": {
     "duration": 0.365987,
     "end_time": "2022-12-12T17:55:32.986527",
     "exception": false,
     "start_time": "2022-12-12T17:55:32.620540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.877771208986107\n",
      "Threshold 0.22 -- 0.8795940486747462\n",
      "Threshold 0.24 -- 0.8789659079712288\n",
      "Threshold 0.26 -- 0.8789659079712288\n",
      "Threshold 0.28 -- 0.8789659079712288\n",
      "Threshold 0.30000000000000004 -- 0.8838678687555426\n",
      "Threshold 0.32000000000000006 -- 0.8887698295398563\n",
      "Threshold 0.3400000000000001 -- 0.8936717903241698\n",
      "Threshold 0.3600000000000001 -- 0.8954946300128092\n",
      "Threshold 0.3800000000000001 -- 0.8954946300128092\n",
      "Threshold 0.40000000000000013 -- 0.8954946300128092\n",
      "Threshold 0.42000000000000015 -- 0.8954946300128092\n",
      "Threshold 0.44000000000000017 -- 0.8948664893092916\n",
      "Threshold 0.4600000000000002 -- 0.8948664893092916\n",
      "Threshold 0.4800000000000002 -- 0.8973174697014484\n",
      "Threshold 0.5000000000000002 -- 0.8973174697014484\n",
      "Threshold 0.5200000000000002 -- 0.8997684500936053\n",
      "Threshold 0.5400000000000003 -- 0.9040422701744014\n",
      "Threshold 0.5600000000000003 -- 0.9058651098630408\n",
      "Threshold 0.5800000000000003 -- 0.90768794955168\n",
      "Threshold 0.6000000000000003 -- 0.90768794955168\n",
      "Threshold 0.6200000000000003 -- 0.9095107892403193\n",
      "Threshold 0.6400000000000003 -- 0.9088826485368017\n",
      "Threshold 0.6600000000000004 -- 0.9137846093211155\n",
      "Threshold 0.6800000000000004 -- 0.9156074490097547\n",
      "Threshold 0.7000000000000004 -- 0.9156074490097547\n",
      "Threshold 0.7200000000000004 -- 0.9143511676027195\n",
      "Threshold 0.7400000000000004 -- 0.9161740072913588\n",
      "Threshold 0.7600000000000005 -- 0.9155458665878411\n",
      "Threshold 0.7800000000000005 -- 0.9222706670607941\n",
      "Threshold 0.8000000000000005 -- 0.9247216474529509\n",
      "Threshold 0.8200000000000005 -- 0.9240935067494334\n",
      "Threshold 0.8400000000000005 -- 0.9240935067494334\n",
      "Threshold 0.8600000000000005 -- 0.9240935067494334\n",
      "Threshold 0.8800000000000006 -- 0.9222090846388806\n",
      "---Optimum Threshold --- 0.8000000000000005 --ROC-- 0.9247216474529509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "step_factor = 0.02 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = lgbm.predict_proba(features_test) #probability of prediction\n",
    "while threshold_value <=0.9: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "    if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(label_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17d6f241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:33.530492Z",
     "iopub.status.busy": "2022-12-12T17:55:33.529826Z",
     "iopub.status.idle": "2022-12-12T17:55:33.642936Z",
     "shell.execute_reply": "2022-12-12T17:55:33.641339Z"
    },
    "papermill": {
     "duration": 0.410849,
     "end_time": "2022-12-12T17:55:33.645617",
     "exception": false,
     "start_time": "2022-12-12T17:55:33.234768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligbm Accuracy Score ->  99.97565429093123\n"
     ]
    }
   ],
   "source": [
    "predictions_lgbm = lgbm.predict(features_train)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"ligbm Accuracy Score -> \",accuracy_score(predictions_lgbm, label_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d149d1",
   "metadata": {
    "papermill": {
     "duration": 0.248012,
     "end_time": "2022-12-12T17:55:34.144364",
     "exception": false,
     "start_time": "2022-12-12T17:55:33.896352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b19e794b",
   "metadata": {
    "papermill": {
     "duration": 0.247352,
     "end_time": "2022-12-12T17:55:34.637802",
     "exception": false,
     "start_time": "2022-12-12T17:55:34.390450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ADA boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "262ac31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:55:35.130190Z",
     "iopub.status.busy": "2022-12-12T17:55:35.129388Z",
     "iopub.status.idle": "2022-12-12T17:56:14.005762Z",
     "shell.execute_reply": "2022-12-12T17:56:14.004720Z"
    },
    "papermill": {
     "duration": 39.422119,
     "end_time": "2022-12-12T17:56:14.305030",
     "exception": false,
     "start_time": "2022-12-12T17:55:34.882911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Accuracy Score ->  93.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       204\n",
      "           1       0.95      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.90      0.89      0.89      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ada.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(features_train,label_train)\n",
    "\n",
    "predictions_ada = clf.predict(features_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Ada Accuracy Score -> \",accuracy_score(predictions_ada, label_test)*100)\n",
    "print(classification_report(label_test,predictions_ada))\n",
    "\n",
    "joblib.dump(clf, \"ada.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d587b",
   "metadata": {
    "papermill": {
     "duration": 0.388292,
     "end_time": "2022-12-12T17:56:14.979126",
     "exception": false,
     "start_time": "2022-12-12T17:56:14.590834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6fad35a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:15.518246Z",
     "iopub.status.busy": "2022-12-12T17:56:15.517889Z",
     "iopub.status.idle": "2022-12-12T17:56:44.397821Z",
     "shell.execute_reply": "2022-12-12T17:56:44.396696Z"
    },
    "papermill": {
     "duration": 29.131569,
     "end_time": "2022-12-12T17:56:44.399979",
     "exception": false,
     "start_time": "2022-12-12T17:56:15.268410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf Accuracy Score ->  94.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       204\n",
      "           1       0.96      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(features_train,label_train)\n",
    "predictions_rf = rf.predict(features_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"rf Accuracy Score -> \",accuracy_score(predictions_rf, label_test)*100)\n",
    "print(classification_report(label_test,predictions_rf))\n",
    "\n",
    "joblib.dump(rf, \"rf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "491e78a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:44.950750Z",
     "iopub.status.busy": "2022-12-12T17:56:44.950363Z",
     "iopub.status.idle": "2022-12-12T17:56:45.002338Z",
     "shell.execute_reply": "2022-12-12T17:56:45.001232Z"
    },
    "papermill": {
     "duration": 0.307848,
     "end_time": "2022-12-12T17:56:45.005935",
     "exception": false,
     "start_time": "2022-12-12T17:56:44.698087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf Accuracy Score ->  94.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       204\n",
      "           1       0.96      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = rf.predict(features_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"rf Accuracy Score -> \",accuracy_score(predictions_rf, label_test)*100)\n",
    "print(classification_report(label_test,predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ac17aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:45.516188Z",
     "iopub.status.busy": "2022-12-12T17:56:45.515496Z",
     "iopub.status.idle": "2022-12-12T17:56:45.661504Z",
     "shell.execute_reply": "2022-12-12T17:56:45.659671Z"
    },
    "papermill": {
     "duration": 0.404485,
     "end_time": "2022-12-12T17:56:45.663836",
     "exception": false,
     "start_time": "2022-12-12T17:56:45.259351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.8454650704502906\n",
      "Threshold 0.22 -- 0.8454650704502906\n",
      "Threshold 0.24 -- 0.8491107498275692\n",
      "Threshold 0.26 -- 0.8552074095970046\n",
      "Threshold 0.28 -- 0.8619322100699576\n",
      "Threshold 0.30000000000000004 -- 0.8619322100699576\n",
      "Threshold 0.32000000000000006 -- 0.8637550497585968\n",
      "Threshold 0.3400000000000001 -- 0.8667725884323578\n",
      "Threshold 0.3600000000000001 -- 0.8802221893782639\n",
      "Threshold 0.3800000000000001 -- 0.8851241501625777\n",
      "Threshold 0.40000000000000013 -- 0.8844960094590602\n",
      "Threshold 0.42000000000000015 -- 0.8838678687555426\n",
      "Threshold 0.44000000000000017 -- 0.8856907084441817\n",
      "Threshold 0.4600000000000002 -- 0.8893363878214603\n",
      "Threshold 0.4800000000000002 -- 0.8960611882944132\n",
      "Threshold 0.5000000000000002 -- 0.8985121686865701\n",
      "Threshold 0.5200000000000002 -- 0.9034141294708838\n",
      "Threshold 0.5400000000000003 -- 0.9021578480638487\n",
      "Threshold 0.5600000000000003 -- 0.9033525470489704\n",
      "Threshold 0.5800000000000003 -- 0.9076263671297665\n",
      "Threshold 0.6000000000000003 -- 0.9100773475219234\n",
      "Threshold 0.6200000000000003 -- 0.9112720465070452\n",
      "Threshold 0.6400000000000003 -- 0.9100157651000098\n",
      "Threshold 0.6600000000000004 -- 0.9118386047886491\n",
      "Threshold 0.6800000000000004 -- 0.9092644595526653\n",
      "Threshold 0.7000000000000004 -- 0.9054956153315598\n",
      "Threshold 0.7200000000000004 -- 0.9091412947088383\n",
      "Threshold 0.7400000000000004 -- 0.9072568725982855\n",
      "Threshold 0.7600000000000005 -- 0.9047443097842152\n",
      "Threshold 0.7800000000000005 -- 0.9028598876736623\n",
      "Threshold 0.8000000000000005 -- 0.895950339934969\n",
      "Threshold 0.8200000000000005 -- 0.8871563700857228\n",
      "Threshold 0.8400000000000005 -- 0.8802468223470292\n",
      "Threshold 0.8600000000000005 -- 0.8732141097645088\n",
      "Threshold 0.8800000000000006 -- 0.8598999901468126\n",
      "---Optimum Threshold --- 0.6600000000000004 --ROC-- 0.9118386047886491\n"
     ]
    }
   ],
   "source": [
    "step_factor = 0.02 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = rf.predict_proba(features_test) #probability of prediction\n",
    "while threshold_value <=0.9: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "    if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(label_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a01611c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:46.214831Z",
     "iopub.status.busy": "2022-12-12T17:56:46.214456Z",
     "iopub.status.idle": "2022-12-12T17:56:46.218531Z",
     "shell.execute_reply": "2022-12-12T17:56:46.217554Z"
    },
    "papermill": {
     "duration": 0.304285,
     "end_time": "2022-12-12T17:56:46.220746",
     "exception": false,
     "start_time": "2022-12-12T17:56:45.916461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test['predicted_label'] = predictions_rf\n",
    "# df_test.to_csv('test_predict.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b679ea71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:46.725170Z",
     "iopub.status.busy": "2022-12-12T17:56:46.724808Z",
     "iopub.status.idle": "2022-12-12T17:56:46.729152Z",
     "shell.execute_reply": "2022-12-12T17:56:46.728115Z"
    },
    "papermill": {
     "duration": 0.260557,
     "end_time": "2022-12-12T17:56:46.731502",
     "exception": false,
     "start_time": "2022-12-12T17:56:46.470945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130cf52",
   "metadata": {
    "papermill": {
     "duration": 0.252718,
     "end_time": "2022-12-12T17:56:47.236716",
     "exception": false,
     "start_time": "2022-12-12T17:56:46.983998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "218a5b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:56:47.967641Z",
     "iopub.status.busy": "2022-12-12T17:56:47.967112Z",
     "iopub.status.idle": "2022-12-12T17:58:22.438923Z",
     "shell.execute_reply": "2022-12-12T17:58:22.437839Z"
    },
    "papermill": {
     "duration": 95.209285,
     "end_time": "2022-12-12T17:58:22.698778",
     "exception": false,
     "start_time": "2022-12-12T17:56:47.489493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy Score of train set->  99.97565429093123\n",
      "xgb Accuracy Score ->  94.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       204\n",
      "           1       0.96      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb = xgb.XGBClassifier()\n",
    "xgb.fit(features_train,label_train)\n",
    "y_train_predict = xgb.predict(features_train)\n",
    "print(\"XGB Accuracy Score of train set-> \",accuracy_score(label_train, y_train_predict)*100)\n",
    "\n",
    "y_test_predict = xgb.predict(features_test)\n",
    "print(\"xgb Accuracy Score -> \",accuracy_score(label_test,y_test_predict)*100)\n",
    "print(classification_report(label_test,y_test_predict))\n",
    "\n",
    "joblib.dump(xgb, \"xgb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "659599ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:23.197524Z",
     "iopub.status.busy": "2022-12-12T17:58:23.197147Z",
     "iopub.status.idle": "2022-12-12T17:58:23.203932Z",
     "shell.execute_reply": "2022-12-12T17:58:23.202938Z"
    },
    "papermill": {
     "duration": 0.258131,
     "end_time": "2022-12-12T17:58:23.205825",
     "exception": false,
     "start_time": "2022-12-12T17:58:22.947694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb Accuracy Score ->  94.1\n"
     ]
    }
   ],
   "source": [
    "print(\"xgb Accuracy Score -> \",accuracy_score(label_test,y_test_predict)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23395bbb",
   "metadata": {
    "papermill": {
     "duration": 0.255644,
     "end_time": "2022-12-12T17:58:23.710167",
     "exception": false,
     "start_time": "2022-12-12T17:58:23.454523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CAT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "390503ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:24.252652Z",
     "iopub.status.busy": "2022-12-12T17:58:24.252288Z",
     "iopub.status.idle": "2022-12-12T17:58:24.256802Z",
     "shell.execute_reply": "2022-12-12T17:58:24.255879Z"
    },
    "papermill": {
     "duration": 0.299903,
     "end_time": "2022-12-12T17:58:24.258760",
     "exception": false,
     "start_time": "2022-12-12T17:58:23.958857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# clf = CatBoostClassifier(task_type = \"GPU\", iterations = 1100,depth = 15)\n",
    "#\n",
    "# # ,iterations=1000,learning_rate = 0.15,depth =10)\n",
    "# # , ,cat_features = LIST_FEAT1 + LIST_FEAT2 + LIST_FEAT5 + LIST_FEAT6 + LIST_FEAT7 + LIST_FEAT8)\n",
    "# clf.fit(features_train,label_train)\n",
    "# y_train_predict = clf.predict(features_train)\n",
    "# print(\"CBoost Accuracy Score of train set-> \",accuracy_score(label_train, y_train_predict)*100)\n",
    "#\n",
    "# y_test_predict = clf.predict(features_test)\n",
    "# print(classification_report(label_test,y_test_predict))\n",
    "#\n",
    "# joblib.dump(clf, \"catboost.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a33be",
   "metadata": {
    "papermill": {
     "duration": 0.248747,
     "end_time": "2022-12-12T17:58:24.758287",
     "exception": false,
     "start_time": "2022-12-12T17:58:24.509540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24705bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:25.256613Z",
     "iopub.status.busy": "2022-12-12T17:58:25.256250Z",
     "iopub.status.idle": "2022-12-12T17:58:32.383547Z",
     "shell.execute_reply": "2022-12-12T17:58:32.382627Z"
    },
    "papermill": {
     "duration": 7.378999,
     "end_time": "2022-12-12T17:58:32.385629",
     "exception": false,
     "start_time": "2022-12-12T17:58:25.006630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  94.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "SVM.fit(features_train,label_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(features_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, label_test)*100)\n",
    "\n",
    "joblib.dump(SVM, \"svm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca7d7d",
   "metadata": {
    "papermill": {
     "duration": 0.249594,
     "end_time": "2022-12-12T17:58:32.941464",
     "exception": false,
     "start_time": "2022-12-12T17:58:32.691870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81aee459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:33.441091Z",
     "iopub.status.busy": "2022-12-12T17:58:33.440725Z",
     "iopub.status.idle": "2022-12-12T17:58:34.233543Z",
     "shell.execute_reply": "2022-12-12T17:58:34.231461Z"
    },
    "papermill": {
     "duration": 1.048266,
     "end_time": "2022-12-12T17:58:34.240235",
     "exception": false,
     "start_time": "2022-12-12T17:58:33.191969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG Accuracy Score of train set->  94.96043822276323\n",
      "LG Accuracy Score ->  93.30000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       204\n",
      "           1       0.96      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.90      0.89      0.90      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lg.pkl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression()\n",
    "\n",
    "reg.fit(features_train,label_train)\n",
    "y_train_predict = reg.predict(features_train)\n",
    "print(\"LG Accuracy Score of train set-> \",accuracy_score(label_train, y_train_predict)*100)\n",
    "\n",
    "y_test_predict = reg.predict(features_test)\n",
    "print(\"LG Accuracy Score -> \",accuracy_score(label_test,y_test_predict)*100)\n",
    "print(classification_report(label_test,y_test_predict))\n",
    "\n",
    "joblib.dump(reg, \"lg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f41d3353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:34.881426Z",
     "iopub.status.busy": "2022-12-12T17:58:34.881077Z",
     "iopub.status.idle": "2022-12-12T17:58:34.904136Z",
     "shell.execute_reply": "2022-12-12T17:58:34.902674Z"
    },
    "papermill": {
     "duration": 0.339479,
     "end_time": "2022-12-12T17:58:34.908182",
     "exception": false,
     "start_time": "2022-12-12T17:58:34.568703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG Accuracy Score ->  93.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       204\n",
      "           1       0.96      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.90      0.90      0.90      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n",
      "0.8965661641541038\n"
     ]
    }
   ],
   "source": [
    "predictions_vt = (reg.predict_proba(features_test)[:,1] >= 0.51).astype(bool)\n",
    "\n",
    "print(\"LG Accuracy Score -> \",accuracy_score(predictions_vt, label_test)*100)\n",
    "print(classification_report(label_test,predictions_vt))\n",
    "print(roc_auc_score(label_test, predictions_vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f61ff356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:35.477924Z",
     "iopub.status.busy": "2022-12-12T17:58:35.477539Z",
     "iopub.status.idle": "2022-12-12T17:58:35.646277Z",
     "shell.execute_reply": "2022-12-12T17:58:35.645134Z"
    },
    "papermill": {
     "duration": 0.422099,
     "end_time": "2022-12-12T17:58:35.648530",
     "exception": false,
     "start_time": "2022-12-12T17:58:35.226431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.8748152527342594\n",
      "Threshold 0.22 -- 0.8760099517193811\n",
      "Threshold 0.24 -- 0.8778327914080204\n",
      "Threshold 0.26 -- 0.8790274903931421\n",
      "Threshold 0.28 -- 0.8808503300817814\n",
      "Threshold 0.30000000000000004 -- 0.8814168883633855\n",
      "Threshold 0.32000000000000006 -- 0.8863188491476993\n",
      "Threshold 0.3400000000000001 -- 0.8856907084441817\n",
      "Threshold 0.3600000000000001 -- 0.8881416888363386\n",
      "Threshold 0.3800000000000001 -- 0.8899645285249779\n",
      "Threshold 0.40000000000000013 -- 0.8911592275100996\n",
      "Threshold 0.42000000000000015 -- 0.8923539264952213\n",
      "Threshold 0.44000000000000017 -- 0.8935486254803429\n",
      "Threshold 0.4600000000000002 -- 0.8929204847768252\n",
      "Threshold 0.4800000000000002 -- 0.8953714651689821\n",
      "Threshold 0.5000000000000002 -- 0.894115183761947\n",
      "Threshold 0.5200000000000002 -- 0.8965661641541038\n",
      "Threshold 0.5400000000000003 -- 0.8940536013400335\n",
      "Threshold 0.5600000000000003 -- 0.8965045817321904\n",
      "Threshold 0.5800000000000003 -- 0.9026012415016257\n",
      "Threshold 0.6000000000000003 -- 0.9068750615824219\n",
      "Threshold 0.6200000000000003 -- 0.9092644595526653\n",
      "Threshold 0.6400000000000003 -- 0.9110872992413046\n",
      "Threshold 0.6600000000000004 -- 0.9092028771307519\n",
      "Threshold 0.6800000000000004 -- 0.9116538575229087\n",
      "Threshold 0.7000000000000004 -- 0.9109641343974776\n",
      "Threshold 0.7200000000000004 -- 0.9097078529904423\n",
      "Threshold 0.7400000000000004 -- 0.9084515715834071\n",
      "Threshold 0.7600000000000005 -- 0.9059390087693369\n",
      "Threshold 0.7800000000000005 -- 0.9033648635333529\n",
      "---Optimum Threshold --- 0.6800000000000004 --ROC-- 0.9116538575229087\n"
     ]
    }
   ],
   "source": [
    "step_factor = 0.02 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = reg.predict_proba(features_test) #probability of prediction\n",
    "while threshold_value <=0.8: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "    if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(label_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3d607",
   "metadata": {
    "papermill": {
     "duration": 0.248087,
     "end_time": "2022-12-12T17:58:36.155590",
     "exception": false,
     "start_time": "2022-12-12T17:58:35.907503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfe0aa18",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:36.701430Z",
     "iopub.status.busy": "2022-12-12T17:58:36.701070Z",
     "iopub.status.idle": "2022-12-12T17:58:48.958104Z",
     "shell.execute_reply": "2022-12-12T17:58:48.956945Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.562515,
     "end_time": "2022-12-12T17:58:48.964693",
     "exception": false,
     "start_time": "2022-12-12T17:58:36.402178",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy Score of train set->  94.71698113207547\n",
      "MLP Accuracy Score ->  94.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       204\n",
      "           1       0.96      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mlp.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation = \"logistic\", alpha = 0.1, hidden_layer_sizes = (10, 10, 10),\n",
    "                            learning_rate = \"constant\", max_iter = 300, random_state = 42)\n",
    "\n",
    "mlp.fit(features_train,label_train)\n",
    "y_train_predict = mlp.predict(features_train)\n",
    "print(\"MLP Accuracy Score of train set-> \",accuracy_score(label_train, y_train_predict)*100)\n",
    "\n",
    "y_test_predict = mlp.predict(features_test)\n",
    "print(\"MLP Accuracy Score -> \",accuracy_score(label_test,y_test_predict)*100)\n",
    "print(classification_report(label_test,y_test_predict))\n",
    "\n",
    "joblib.dump(reg, \"mlp.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f53868",
   "metadata": {
    "papermill": {
     "duration": 0.268794,
     "end_time": "2022-12-12T17:58:49.664473",
     "exception": false,
     "start_time": "2022-12-12T17:58:49.395679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06f4f9ce",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:58:50.170274Z",
     "iopub.status.busy": "2022-12-12T17:58:50.169924Z",
     "iopub.status.idle": "2022-12-12T17:59:09.682930Z",
     "shell.execute_reply": "2022-12-12T17:59:09.681326Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 19.769626,
     "end_time": "2022-12-12T17:59:09.685519",
     "exception": false,
     "start_time": "2022-12-12T17:58:49.915893",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC Accuracy Score of train set->  92.87888009738283\n",
      "NuSVC Accuracy Score ->  94.69999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       204\n",
      "           1       0.96      0.97      0.97       796\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.92      0.91      0.92      1000\n",
      "weighted avg       0.95      0.95      0.95      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nusvc.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "nu_svc = NuSVC(degree = 1, kernel = \"linear\", nu = 0.1, probability = True, max_iter=300)\n",
    "\n",
    "nu_svc.fit(features_train,label_train)\n",
    "y_train_predict = nu_svc.predict(features_train)\n",
    "print(\"NuSVC Accuracy Score of train set-> \",accuracy_score(label_train, y_train_predict)*100)\n",
    "\n",
    "y_test_predict = nu_svc.predict(features_test)\n",
    "print(\"NuSVC Accuracy Score -> \",accuracy_score(label_test,y_test_predict)*100)\n",
    "print(classification_report(label_test,y_test_predict))\n",
    "\n",
    "joblib.dump(reg, \"nusvc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0bf2e0",
   "metadata": {
    "papermill": {
     "duration": 0.248924,
     "end_time": "2022-12-12T17:59:10.189893",
     "exception": false,
     "start_time": "2022-12-12T17:59:09.940969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cc68624",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-12T17:59:10.899782Z",
     "iopub.status.busy": "2022-12-12T17:59:10.899336Z",
     "iopub.status.idle": "2022-12-12T17:59:10.909114Z",
     "shell.execute_reply": "2022-12-12T17:59:10.908156Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.423693,
     "end_time": "2022-12-12T17:59:10.911085",
     "exception": false,
     "start_time": "2022-12-12T17:59:10.487392",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Building the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    embed = Embedding(input_dim = 60000, output_dim = 20, input_length = features_train.shape[1])\n",
    "    model.add(embed)\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(200, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(200, return_sequences = True)))\n",
    "    model.add(AttentionWithContext())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68cbb8",
   "metadata": {
    "papermill": {
     "duration": 0.249875,
     "end_time": "2022-12-12T17:59:11.481962",
     "exception": false,
     "start_time": "2022-12-12T17:59:11.232087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24b7d5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T17:59:12.025472Z",
     "iopub.status.busy": "2022-12-12T17:59:12.025009Z",
     "iopub.status.idle": "2022-12-12T18:01:32.395042Z",
     "shell.execute_reply": "2022-12-12T18:01:32.393750Z"
    },
    "papermill": {
     "duration": 140.993027,
     "end_time": "2022-12-12T18:01:32.724026",
     "exception": false,
     "start_time": "2022-12-12T17:59:11.730999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Accuracy Score ->  93.89999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       204\n",
      "           1       0.96      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.91      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500,min_samples_leaf=2,\n",
    "                                min_samples_split= 10, max_features = 'sqrt', criterion = 'entropy', bootstrap= True,\n",
    "                              random_state=42)\n",
    "lgbm = LGBMClassifier(boosting_type = 'goss', learning_rate = 0.05, n_estimators = 200,num_leaves = 20, scale_pos_weight = 0.7)\n",
    "lg = LogisticRegression(max_iter=200)\n",
    "xgb = XGBClassifier(n_estimators = 200, max_depth=20,tree_method=\"hist\")\n",
    "svm = SVC(kernel='linear', probability=True, gamma=0.2, degree=1, verbose=True, tol=1e-5)\n",
    "ada = AdaBoostClassifier(n_estimators=200, random_state=1, learning_rate=1e-5)\n",
    "mlp = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10),\n",
    "                            learning_rate = \"constant\", max_iter = 2000, random_state = 1000)\n",
    "nu_svc = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
    "\n",
    "rf = joblib.load(\"rf.pkl\")\n",
    "lg = joblib.load(\"lg.pkl\")\n",
    "xgb = joblib.load(\"xgb.pkl\")\n",
    "svm = joblib.load(\"svm.pkl\")\n",
    "ada = joblib.load(\"ada.pkl\")\n",
    "mlp = joblib.load(\"mlp.pkl\")\n",
    "nu_svc = joblib.load(\"nusvc.pkl\")\n",
    "\n",
    "lstm = KerasClassifier(build_fn= lambda: create_model())\n",
    "lstm._estimator_type = \"classifier\"\n",
    "\n",
    "# bert = KerasClassifier(build_fn = lambda: create_bert())\n",
    "# bert._estimator_type = 'classifier'\n",
    "\n",
    "estimator = []\n",
    "# estimator.append(('LR', \n",
    "#                   LogisticRegression(solver ='lbfgs', \n",
    "#                                      multi_class ='multinomial', \n",
    "#                                      max_iter = 200)))\n",
    "\n",
    "estimator.append(('RF', rf))\n",
    "estimator.append(('XGB', xgb))\n",
    "estimator.append(('LGBM', lgbm))\n",
    "# estimator.append(('MLP', mlp))\n",
    "# estimator.append(('SVM', svm ))\n",
    "# estimator.append(('NuSVC', nu_svc))\n",
    "estimator.append(('LG', lg))\n",
    "# estimator.append(('LSTM', lstm))\n",
    "# estimator.append(('ADA', ada))\n",
    "# estimator.append(('BERT', bert))\n",
    "# estimator.append(('LSTM', lstm))\n",
    "\n",
    "# voting ='soft'\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "vot_hard.fit(features_train,label_train)\n",
    "y_pred = vot_hard.predict(features_test)\n",
    "                 \n",
    "print(\"Voting Accuracy Score -> \",accuracy_score(y_pred, label_test)*100)\n",
    "\n",
    "print(classification_report(label_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf409fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:01:33.236662Z",
     "iopub.status.busy": "2022-12-12T18:01:33.236297Z",
     "iopub.status.idle": "2022-12-12T18:01:33.332593Z",
     "shell.execute_reply": "2022-12-12T18:01:33.331364Z"
    },
    "papermill": {
     "duration": 0.352548,
     "end_time": "2022-12-12T18:01:33.336405",
     "exception": false,
     "start_time": "2022-12-12T18:01:32.983857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting Accuracy Score ->  93.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       204\n",
      "           1       0.96      0.96      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.90      0.90      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n",
      "0.8990787269681743\n"
     ]
    }
   ],
   "source": [
    "predictions_vt = (vot_hard.predict_proba(features_test)[:,1] >= 0.47).astype(bool)\n",
    "\n",
    "print(\"voting Accuracy Score -> \",accuracy_score(predictions_vt, label_test)*100)\n",
    "print(classification_report(label_test,predictions_vt))\n",
    "print(roc_auc_score(label_test, predictions_vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4d3f8cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:01:33.955219Z",
     "iopub.status.busy": "2022-12-12T18:01:33.954856Z",
     "iopub.status.idle": "2022-12-12T18:01:34.201550Z",
     "shell.execute_reply": "2022-12-12T18:01:34.199713Z"
    },
    "papermill": {
     "duration": 0.548034,
     "end_time": "2022-12-12T18:01:34.203774",
     "exception": false,
     "start_time": "2022-12-12T18:01:33.655740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.8723026899201891\n",
      "Threshold 0.22 -- 0.8723026899201891\n",
      "Threshold 0.24 -- 0.8808503300817814\n",
      "Threshold 0.26 -- 0.8826731697704208\n",
      "Threshold 0.28 -- 0.8869469898512169\n",
      "Threshold 0.30000000000000004 -- 0.8863188491476993\n",
      "Threshold 0.32000000000000006 -- 0.8850625677406642\n",
      "Threshold 0.3400000000000001 -- 0.8899645285249779\n",
      "Threshold 0.3600000000000001 -- 0.8899645285249779\n",
      "Threshold 0.3800000000000001 -- 0.8893363878214603\n",
      "Threshold 0.40000000000000013 -- 0.8887082471179427\n",
      "Threshold 0.42000000000000015 -- 0.8985121686865701\n",
      "Threshold 0.44000000000000017 -- 0.9009631490787271\n",
      "Threshold 0.4600000000000002 -- 0.8997068676716918\n",
      "Threshold 0.4800000000000002 -- 0.8990787269681743\n",
      "Threshold 0.5000000000000002 -- 0.9015297073603311\n",
      "Threshold 0.5200000000000002 -- 0.9033525470489704\n",
      "Threshold 0.5400000000000003 -- 0.9058035274411271\n",
      "Threshold 0.5600000000000003 -- 0.9058035274411271\n",
      "Threshold 0.5800000000000003 -- 0.908254507833284\n",
      "Threshold 0.6000000000000003 -- 0.910705488225441\n",
      "Threshold 0.6200000000000003 -- 0.9180584294019115\n",
      "Threshold 0.6400000000000003 -- 0.9198812690905508\n",
      "Threshold 0.6600000000000004 -- 0.9223322494827076\n",
      "Threshold 0.6800000000000004 -- 0.9223322494827076\n",
      "Threshold 0.7000000000000004 -- 0.9204478273721548\n",
      "Threshold 0.7200000000000004 -- 0.9204478273721548\n",
      "Threshold 0.7400000000000004 -- 0.9191915459651196\n",
      "Threshold 0.7600000000000005 -- 0.9179352645580845\n",
      "Threshold 0.7800000000000005 -- 0.9197581042467238\n",
      "Threshold 0.8000000000000005 -- 0.917873682136171\n",
      "Threshold 0.8200000000000005 -- 0.9178120997142576\n",
      "Threshold 0.8400000000000005 -- 0.9195733569809833\n",
      "Threshold 0.8600000000000005 -- 0.913920090649325\n",
      "Threshold 0.8800000000000006 -- 0.9076386836141491\n",
      "---Optimum Threshold --- 0.6600000000000004 --ROC-- 0.9223322494827076\n"
     ]
    }
   ],
   "source": [
    "step_factor = 0.02 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = vot_hard.predict_proba(features_test) #probability of prediction\n",
    "while threshold_value <=0.9: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "    if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(label_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab942331",
   "metadata": {
    "papermill": {
     "duration": 0.249963,
     "end_time": "2022-12-12T18:01:34.704167",
     "exception": false,
     "start_time": "2022-12-12T18:01:34.454204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92760404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:01:35.202782Z",
     "iopub.status.busy": "2022-12-12T18:01:35.202389Z",
     "iopub.status.idle": "2022-12-12T18:20:33.863498Z",
     "shell.execute_reply": "2022-12-12T18:20:33.861642Z"
    },
    "papermill": {
     "duration": 1138.913341,
     "end_time": "2022-12-12T18:20:33.865927",
     "exception": false,
     "start_time": "2022-12-12T18:01:34.952586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:03:55.331213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:55.333215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:55.333776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:55.334534: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 18:03:55.334835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:55.335363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:55.335891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:56.731861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:56.732549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:56.733109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 18:03:56.734763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8943 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context (Atte (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:03:58.219180: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25236480 exceeds 10% of free system memory.\n",
      "2022-12-12 18:03:58.255137: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25236480 exceeds 10% of free system memory.\n",
      "2022-12-12 18:03:58.281868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-12-12 18:04:04.263998: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 60s 207ms/step - loss: 0.6388 - accuracy: 0.6693\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:14:40.078600: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 20189184 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 48s 208ms/step - loss: 0.6414 - accuracy: 0.6677\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:16:12.980646: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 20189184 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 48s 206ms/step - loss: 0.6390 - accuracy: 0.6681\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context_3 (At (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 18:17:46.997451: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 20189184 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 48s 208ms/step - loss: 0.6397 - accuracy: 0.6681\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context_4 (At (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "206/206 [==============================] - 47s 206ms/step - loss: 0.6388 - accuracy: 0.6700\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 768, 20)           1200000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 768, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 768, 400)          353600    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 768, 400)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 768, 400)          961600    \n",
      "_________________________________________________________________\n",
      "attention_with_context_5 (At (None, 400)               160800    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,012,897\n",
      "Trainable params: 3,012,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "206/206 [==============================] - 48s 207ms/step - loss: 0.6388 - accuracy: 0.6695\n",
      "ST Accuracy Score ->  93.89999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       204\n",
      "           1       0.95      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.89      0.90      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    # ('RF', rf),\n",
    "    # ('XGB', xgb),\n",
    "    # ('LGBM', lgbm),\n",
    "    # ('SVM', svm),\n",
    "    (\"RF\", rf),\n",
    "    ('XGB', xgb),\n",
    "    ('LGBM', lgbm),\n",
    "    ('LSTM', lstm),\n",
    "    # ('NuSVC', nu_svc)\n",
    "]\n",
    "\n",
    "st = StackingClassifier(estimators=estimators, final_estimator = ada)\n",
    "st.fit(features_train,label_train)\n",
    "y_pred = st.predict(features_test)\n",
    "                 \n",
    "print(\"ST Accuracy Score -> \",accuracy_score(y_pred, label_test)*100)\n",
    "\n",
    "print(classification_report(label_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37cdaea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:20:34.606614Z",
     "iopub.status.busy": "2022-12-12T18:20:34.606235Z",
     "iopub.status.idle": "2022-12-12T18:20:37.301148Z",
     "shell.execute_reply": "2022-12-12T18:20:37.299465Z"
    },
    "papermill": {
     "duration": 3.06652,
     "end_time": "2022-12-12T18:20:37.303341",
     "exception": false,
     "start_time": "2022-12-12T18:20:34.236821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST Accuracy Score ->  93.89999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85       204\n",
      "           1       0.95      0.97      0.96       796\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.91      0.89      0.90      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n",
      "0.894238348605774\n"
     ]
    }
   ],
   "source": [
    "predictions_st = (st.predict_proba(features_test)[:,1] >= 0.5).astype(bool)\n",
    "\n",
    "print(\"ST Accuracy Score -> \",accuracy_score(predictions_st, label_test)*100)\n",
    "print(classification_report(label_test,predictions_st))\n",
    "print(roc_auc_score(label_test, predictions_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "598df118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:20:37.939208Z",
     "iopub.status.busy": "2022-12-12T18:20:37.938829Z",
     "iopub.status.idle": "2022-12-12T18:20:40.711464Z",
     "shell.execute_reply": "2022-12-12T18:20:40.708848Z"
    },
    "papermill": {
     "duration": 3.09292,
     "end_time": "2022-12-12T18:20:40.713859",
     "exception": false,
     "start_time": "2022-12-12T18:20:37.620939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.2 -- 0.5\n",
      "Threshold 0.22 -- 0.5\n",
      "Threshold 0.24 -- 0.5\n",
      "Threshold 0.26 -- 0.5\n",
      "Threshold 0.28 -- 0.5\n",
      "Threshold 0.30000000000000004 -- 0.5\n",
      "Threshold 0.32000000000000006 -- 0.5\n",
      "Threshold 0.3400000000000001 -- 0.5\n",
      "Threshold 0.3600000000000001 -- 0.5\n",
      "Threshold 0.3800000000000001 -- 0.5581953887082471\n",
      "Threshold 0.40000000000000013 -- 0.5704502906690315\n",
      "Threshold 0.42000000000000015 -- 0.5704502906690315\n",
      "Threshold 0.44000000000000017 -- 0.5704502906690315\n",
      "Threshold 0.4600000000000002 -- 0.5704502906690315\n",
      "Threshold 0.4800000000000002 -- 0.6739580254212238\n",
      "Threshold 0.5000000000000002 -- 0.894238348605774\n",
      "Threshold 0.5200000000000002 -- 0.8193294905902059\n",
      "Threshold 0.5400000000000003 -- 0.5396344467435216\n",
      "Threshold 0.5600000000000003 -- 0.5396344467435216\n",
      "Threshold 0.5800000000000003 -- 0.5396344467435216\n",
      "Threshold 0.6000000000000003 -- 0.5396344467435216\n",
      "Threshold 0.6200000000000003 -- 0.5396344467435216\n",
      "Threshold 0.6400000000000003 -- 0.5396344467435216\n",
      "Threshold 0.6600000000000004 -- 0.5396344467435216\n",
      "Threshold 0.6800000000000004 -- 0.5396344467435216\n",
      "Threshold 0.7000000000000004 -- 0.5\n",
      "Threshold 0.7200000000000004 -- 0.5\n",
      "Threshold 0.7400000000000004 -- 0.5\n",
      "Threshold 0.7600000000000005 -- 0.5\n",
      "Threshold 0.7800000000000005 -- 0.5\n",
      "---Optimum Threshold --- 0.5000000000000002 --ROC-- 0.894238348605774\n"
     ]
    }
   ],
   "source": [
    "step_factor = 0.02 \n",
    "threshold_value = 0.2 \n",
    "roc_score=0\n",
    "predicted_proba = st.predict_proba(features_test) #probability of prediction\n",
    "while threshold_value <=0.8: #continue to check best threshold upto probability 0.8\n",
    "    temp_thresh = threshold_value\n",
    "    predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "    print('Threshold',temp_thresh,'--',roc_auc_score(label_test, predicted))\n",
    "    if roc_score<roc_auc_score(label_test, predicted): #store the threshold for best classification\n",
    "        roc_score = roc_auc_score(label_test, predicted)\n",
    "        thrsh_score = threshold_value\n",
    "    threshold_value = threshold_value + step_factor\n",
    "print('---Optimum Threshold ---',thrsh_score,'--ROC--',roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4655179b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:20:41.354494Z",
     "iopub.status.busy": "2022-12-12T18:20:41.353718Z",
     "iopub.status.idle": "2022-12-12T18:20:41.362587Z",
     "shell.execute_reply": "2022-12-12T18:20:41.361677Z"
    },
    "papermill": {
     "duration": 0.331413,
     "end_time": "2022-12-12T18:20:41.364811",
     "exception": false,
     "start_time": "2022-12-12T18:20:41.033398",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert_fine_tuning(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=500, bias=True)\n",
       "    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "    (5): Linear(in_features=500, out_features=2, bias=True)\n",
       "  )\n",
       "  (criterior): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42952cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:20:42.012115Z",
     "iopub.status.busy": "2022-12-12T18:20:42.011750Z",
     "iopub.status.idle": "2022-12-12T18:20:42.124606Z",
     "shell.execute_reply": "2022-12-12T18:20:42.123702Z"
    },
    "papermill": {
     "duration": 0.433597,
     "end_time": "2022-12-12T18:20:42.126656",
     "exception": false,
     "start_time": "2022-12-12T18:20:41.693059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9069, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.read_csv('/kaggle/input/mlkaggle/vuong_test.csv')\n",
    "select_indices = list(np.where(df_submit.loc[:,\"Comment\"].isnull()))\n",
    "for item in select_indices[0]: #select_indices is an array, you need to access the first element to print the indexes\n",
    "    print(item)\n",
    "df_submit = df_submit.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9708612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:20:42.813891Z",
     "iopub.status.busy": "2022-12-12T18:20:42.813512Z",
     "iopub.status.idle": "2022-12-12T18:21:23.416785Z",
     "shell.execute_reply": "2022-12-12T18:21:23.415144Z"
    },
    "papermill": {
     "duration": 40.925852,
     "end_time": "2022-12-12T18:21:23.419132",
     "exception": false,
     "start_time": "2022-12-12T18:20:42.493280",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [    0  2272  4451  6639  1947 34106 21834 21913  6620  1947    58    25\n",
      "    97  1006    51   133  1329 11206  3628  1152   946   475    15    36\n",
      "   946    85  4578  1006    66    10    76    18   533  2905    58  1329\n",
      "    45   700  8210  2169     8  1236  8017  1595    25   189    85    54\n",
      "    68    17    55  1279    51    25  1005 14307  4453    54  5634   204\n",
      "  3628  3787  1595  1521  5119  3787  1595  1521  5119     2     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "len padded: (5103, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([5103, 256])\n",
      "(32, 768)\n",
      "(64, 768)\n",
      "(96, 768)\n",
      "(128, 768)\n",
      "(160, 768)\n",
      "(192, 768)\n",
      "(224, 768)\n",
      "(256, 768)\n",
      "(288, 768)\n",
      "(320, 768)\n",
      "(352, 768)\n",
      "(384, 768)\n",
      "(416, 768)\n",
      "(448, 768)\n",
      "(480, 768)\n",
      "(512, 768)\n",
      "(544, 768)\n",
      "(576, 768)\n",
      "(608, 768)\n",
      "(640, 768)\n",
      "(672, 768)\n",
      "(704, 768)\n",
      "(736, 768)\n",
      "(768, 768)\n",
      "(800, 768)\n",
      "(832, 768)\n",
      "(864, 768)\n",
      "(896, 768)\n",
      "(928, 768)\n",
      "(960, 768)\n",
      "(992, 768)\n",
      "(1024, 768)\n",
      "(1056, 768)\n",
      "(1088, 768)\n",
      "(1120, 768)\n",
      "(1152, 768)\n",
      "(1184, 768)\n",
      "(1216, 768)\n",
      "(1248, 768)\n",
      "(1280, 768)\n",
      "(1312, 768)\n",
      "(1344, 768)\n",
      "(1376, 768)\n",
      "(1408, 768)\n",
      "(1440, 768)\n",
      "(1472, 768)\n",
      "(1504, 768)\n",
      "(1536, 768)\n",
      "(1568, 768)\n",
      "(1600, 768)\n",
      "(1632, 768)\n",
      "(1664, 768)\n",
      "(1696, 768)\n",
      "(1728, 768)\n",
      "(1760, 768)\n",
      "(1792, 768)\n",
      "(1824, 768)\n",
      "(1856, 768)\n",
      "(1888, 768)\n",
      "(1920, 768)\n",
      "(1952, 768)\n",
      "(1984, 768)\n",
      "(2016, 768)\n",
      "(2048, 768)\n",
      "(2080, 768)\n",
      "(2112, 768)\n",
      "(2144, 768)\n",
      "(2176, 768)\n",
      "(2208, 768)\n",
      "(2240, 768)\n",
      "(2272, 768)\n",
      "(2304, 768)\n",
      "(2336, 768)\n",
      "(2368, 768)\n",
      "(2400, 768)\n",
      "(2432, 768)\n",
      "(2464, 768)\n",
      "(2496, 768)\n",
      "(2528, 768)\n",
      "(2560, 768)\n",
      "(2592, 768)\n",
      "(2624, 768)\n",
      "(2656, 768)\n",
      "(2688, 768)\n",
      "(2720, 768)\n",
      "(2752, 768)\n",
      "(2784, 768)\n",
      "(2816, 768)\n",
      "(2848, 768)\n",
      "(2880, 768)\n",
      "(2912, 768)\n",
      "(2944, 768)\n",
      "(2976, 768)\n",
      "(3008, 768)\n",
      "(3040, 768)\n",
      "(3072, 768)\n",
      "(3104, 768)\n",
      "(3136, 768)\n",
      "(3168, 768)\n",
      "(3200, 768)\n",
      "(3232, 768)\n",
      "(3264, 768)\n",
      "(3296, 768)\n",
      "(3328, 768)\n",
      "(3360, 768)\n",
      "(3392, 768)\n",
      "(3424, 768)\n",
      "(3456, 768)\n",
      "(3488, 768)\n",
      "(3520, 768)\n",
      "(3552, 768)\n",
      "(3584, 768)\n",
      "(3616, 768)\n",
      "(3648, 768)\n",
      "(3680, 768)\n",
      "(3712, 768)\n",
      "(3744, 768)\n",
      "(3776, 768)\n",
      "(3808, 768)\n",
      "(3840, 768)\n",
      "(3872, 768)\n",
      "(3904, 768)\n",
      "(3936, 768)\n",
      "(3968, 768)\n",
      "(4000, 768)\n",
      "(4032, 768)\n",
      "(4064, 768)\n",
      "(4096, 768)\n",
      "(4128, 768)\n",
      "(4160, 768)\n",
      "(4192, 768)\n",
      "(4224, 768)\n",
      "(4256, 768)\n",
      "(4288, 768)\n",
      "(4320, 768)\n",
      "(4352, 768)\n",
      "(4384, 768)\n",
      "(4416, 768)\n",
      "(4448, 768)\n",
      "(4480, 768)\n",
      "(4512, 768)\n",
      "(4544, 768)\n",
      "(4576, 768)\n",
      "(4608, 768)\n",
      "(4640, 768)\n",
      "(4672, 768)\n",
      "(4704, 768)\n",
      "(4736, 768)\n",
      "(4768, 768)\n",
      "(4800, 768)\n",
      "(4832, 768)\n",
      "(4864, 768)\n",
      "(4896, 768)\n",
      "(4928, 768)\n",
      "(4960, 768)\n",
      "(4992, 768)\n",
      "(5024, 768)\n",
      "(5056, 768)\n",
      "(5088, 768)\n",
      "(5103, 768)\n",
      "(5103, 768)\n"
     ]
    }
   ],
   "source": [
    "text_sub = df_submit['Comment'].to_list()\n",
    "features_sub = make_bert_features(text_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bd431ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:21:24.124923Z",
     "iopub.status.busy": "2022-12-12T18:21:24.124333Z",
     "iopub.status.idle": "2022-12-12T18:21:24.434309Z",
     "shell.execute_reply": "2022-12-12T18:21:24.432772Z"
    },
    "papermill": {
     "duration": 0.687585,
     "end_time": "2022-12-12T18:21:24.438094",
     "exception": false,
     "start_time": "2022-12-12T18:21:23.750509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_sub = vot_hard.predict_proba(features_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d739d9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:21:25.168442Z",
     "iopub.status.busy": "2022-12-12T18:21:25.168060Z",
     "iopub.status.idle": "2022-12-12T18:21:25.173995Z",
     "shell.execute_reply": "2022-12-12T18:21:25.172729Z"
    },
    "papermill": {
     "duration": 0.334576,
     "end_time": "2022-12-12T18:21:25.176587",
     "exception": false,
     "start_time": "2022-12-12T18:21:24.842011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit['Rating'] = predicted_sub[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "714d747a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:21:25.882783Z",
     "iopub.status.busy": "2022-12-12T18:21:25.882384Z",
     "iopub.status.idle": "2022-12-12T18:21:25.889029Z",
     "shell.execute_reply": "2022-12-12T18:21:25.887963Z"
    },
    "papermill": {
     "duration": 0.388657,
     "end_time": "2022-12-12T18:21:25.892368",
     "exception": false,
     "start_time": "2022-12-12T18:21:25.503711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trà táo 35k cookie socola 38k nước ở đây bình_thường nhưng giá hơi chát ạ không_gian quán giống với nhiều quán khác phục bình_thường chỉ có 2 người phục_vụ đợi nước hơi bị lâu í nói_chung là delio ở nơi khác thì mình không biết thế_nào nhưng ở hồ đắc di thì nhạt quá ạ emo khóc ròng emo khóc ròng '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit['Comment'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69b3a382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:21:26.547408Z",
     "iopub.status.busy": "2022-12-12T18:21:26.547036Z",
     "iopub.status.idle": "2022-12-12T18:21:26.567823Z",
     "shell.execute_reply": "2022-12-12T18:21:26.566942Z"
    },
    "papermill": {
     "duration": 0.346547,
     "end_time": "2022-12-12T18:21:26.569800",
     "exception": false,
     "start_time": "2022-12-12T18:21:26.223253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit[['RevId','Rating']].to_csv('submit_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "384aa68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-12T18:21:27.225407Z",
     "iopub.status.busy": "2022-12-12T18:21:27.225020Z",
     "iopub.status.idle": "2022-12-12T18:21:36.810397Z",
     "shell.execute_reply": "2022-12-12T18:21:36.809303Z"
    },
    "papermill": {
     "duration": 9.91848,
     "end_time": "2022-12-12T18:21:36.815267",
     "exception": false,
     "start_time": "2022-12-12T18:21:26.896787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [    0  4036   364  2977 13740    51  3585    17  1019  1325   246    15\n",
      "   133   123 15370  2263   889  3619  1947    95  2607    51   203  5634\n",
      "    17  2023   566 19505   889 10831  1947    95  2607    51    74    24\n",
      "   137    76   107   566 19505   308     6    17  1834 12291  4481  1917\n",
      "  1947    95    73    54  1236  6625  2008  8813     6    17  1019  1834\n",
      "  1695    14  8861  2114   437    73  1834    68 49833  3030  2857  2537\n",
      "     6  2122  4407    51   139  1498   131    17  1026 16767     7   946\n",
      "  2621   234    51  2475    15  3538    54    44    17   549  2169     8\n",
      "   281  2804    90   523 37973   167    28   946    36  3787  1595  1521\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "len padded: (1000, 256)\n",
      "attention mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Padd =  torch.Size([1000, 256])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.2703  Acc: 1.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "\n",
    "\n",
    "net = b\n",
    "net.eval()\n",
    "Data_test, attention_test = b.tokenize(text_test, label_test)\n",
    "attention = attention_test\n",
    "\n",
    "list_pred = np.array([])\n",
    "            \n",
    "for (inputs, labels), i_attention in tqdm(zip(Data_test, attention)):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    i_attention = i_attention.to(device)\n",
    "    \n",
    "    outputs = b(inputs,i_attention)\n",
    "        \n",
    "    loss = b.criterior(outputs,labels)      \n",
    "        \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "#     print(preds.cpu().numpy())\n",
    "    list_pred = np.append(list_pred,preds.cpu().numpy())\n",
    "        \n",
    "    epoch_loss += loss.item() * inputs.size(0)\n",
    "    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "epoch_loss = epoch_loss / len(Data_test.dataset)\n",
    "epoch_acc = epoch_corrects.double() / len(Data_test.dataset)\n",
    "            \n",
    "print(\" Loss: {:.4f}  Acc: {:.4f}\".format( epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2998.352459,
   "end_time": "2022-12-12T18:21:40.684597",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-12T17:31:42.332138",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ce9fb295a0544d8aa5b1f37057316b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25027e8220ae40c585b91fcf17cf5f05",
       "max": 557.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_94860e5c044b4d50b74c5632160ed22e",
       "value": 557.0
      }
     },
     "19f2a47ebe71422da8aa55d82baa80f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1df85ac61e8b40c8a72da66ef98204af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c560bda07c01431caa1b68a4d2d79bdc",
       "placeholder": "​",
       "style": "IPY_MODEL_fbb17d0b74b042a6bd46aa42168927a3",
       "value": "Downloading: 100%"
      }
     },
     "1f120077a5224f62a7d7252e2c3e2443": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20d0582c13194b1183e9b0360e29e518": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23f1be54aad140dd95e5207f53e5a4d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88bb7a9d96994a54ab76e06de94cee9a",
        "IPY_MODEL_3b0e4deb10b14c069d0a58dd7c0dc7f0",
        "IPY_MODEL_92ed3c95664f4c6ebc7f20de638ff65a"
       ],
       "layout": "IPY_MODEL_713e8b207c054827b337ba396c262185"
      }
     },
     "25027e8220ae40c585b91fcf17cf5f05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bac7800842746f3a320f6b21a51541d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b0e4deb10b14c069d0a58dd7c0dc7f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ca34844c9f204e9b899dfdae4cea5000",
       "max": 1135173.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5e43200538364f7285a168d7370c65e6",
       "value": 1135173.0
      }
     },
     "476dc89c20be4c33903bfa6c22025a7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4ae57c35e05e417dbefc9516ebc1b1d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c735b8cfe8e46aca88e03ca42fdb575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d289512b81724289aa6814c31093eb4c",
        "IPY_MODEL_a4199e8b5ab445408f50bd6f1c31e7c7",
        "IPY_MODEL_7a82ae59173242469a623021cd2a7ddd"
       ],
       "layout": "IPY_MODEL_8a77678237d14d29ad7a4f5d23760458"
      }
     },
     "4ec83d4652874d9aa83ae5a2baa615d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4f73eb452ba34d6185250d4e8e9db03c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "53bd80ca58064f3eb9fd4da4f9a5d241": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1df85ac61e8b40c8a72da66ef98204af",
        "IPY_MODEL_5c03f24c51c34d979c2bd76925439e30",
        "IPY_MODEL_9c1ff68e00f945348f8d41c5f9593e80"
       ],
       "layout": "IPY_MODEL_5b55cf9c4f37403b9b22cd048c53f4c0"
      }
     },
     "5b55cf9c4f37403b9b22cd048c53f4c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c03f24c51c34d979c2bd76925439e30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bac7800842746f3a320f6b21a51541d",
       "max": 895321.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_476dc89c20be4c33903bfa6c22025a7e",
       "value": 895321.0
      }
     },
     "5e43200538364f7285a168d7370c65e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "670cc8b205c449c29c698f367047fa7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b1c543a36564a479c1e0ae21c931505": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "713e8b207c054827b337ba396c262185": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "794dd7be44b4418a93187539379b7fe7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a6b93656e6e43b49c437b1b38e1be88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a82ae59173242469a623021cd2a7ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ae57c35e05e417dbefc9516ebc1b1d8",
       "placeholder": "​",
       "style": "IPY_MODEL_794dd7be44b4418a93187539379b7fe7",
       "value": " 518M/518M [00:10&lt;00:00, 51.7MB/s]"
      }
     },
     "84128c0f43d64712a76e9cedc565107c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88bb7a9d96994a54ab76e06de94cee9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_670cc8b205c449c29c698f367047fa7b",
       "placeholder": "​",
       "style": "IPY_MODEL_f1f625a156e446ebb25d2d36820b10f3",
       "value": "Downloading: 100%"
      }
     },
     "8a77678237d14d29ad7a4f5d23760458": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92ed3c95664f4c6ebc7f20de638ff65a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbec353aaa28410e823520d9ec0b744d",
       "placeholder": "​",
       "style": "IPY_MODEL_7a6b93656e6e43b49c437b1b38e1be88",
       "value": " 1.08M/1.08M [00:00&lt;00:00, 3.12MB/s]"
      }
     },
     "94860e5c044b4d50b74c5632160ed22e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9955f51de8b34e89af1476a6d92d2612": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e16a5b46a32942b1b0cd9d5d438eac40",
        "IPY_MODEL_0ce9fb295a0544d8aa5b1f37057316b2",
        "IPY_MODEL_ee81f07b82dc401eafef395f3093395e"
       ],
       "layout": "IPY_MODEL_ced6c8cc346b417994e83f3007259539"
      }
     },
     "9c1ff68e00f945348f8d41c5f9593e80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_20d0582c13194b1183e9b0360e29e518",
       "placeholder": "​",
       "style": "IPY_MODEL_4ec83d4652874d9aa83ae5a2baa615d1",
       "value": " 874k/874k [00:00&lt;00:00, 2.95MB/s]"
      }
     },
     "a0ef8ac26c2e4013afcea0d6ed3d031c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4199e8b5ab445408f50bd6f1c31e7c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b1c543a36564a479c1e0ae21c931505",
       "max": 542923308.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_19f2a47ebe71422da8aa55d82baa80f7",
       "value": 542923308.0
      }
     },
     "b618b7e579904fdca46346f2ce2d1f67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bbec353aaa28410e823520d9ec0b744d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c560bda07c01431caa1b68a4d2d79bdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca34844c9f204e9b899dfdae4cea5000": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ced6c8cc346b417994e83f3007259539": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d289512b81724289aa6814c31093eb4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e59542406a1943abbc4aa6872818906e",
       "placeholder": "​",
       "style": "IPY_MODEL_4f73eb452ba34d6185250d4e8e9db03c",
       "value": "Downloading: 100%"
      }
     },
     "e16a5b46a32942b1b0cd9d5d438eac40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a0ef8ac26c2e4013afcea0d6ed3d031c",
       "placeholder": "​",
       "style": "IPY_MODEL_b618b7e579904fdca46346f2ce2d1f67",
       "value": "Downloading: 100%"
      }
     },
     "e59542406a1943abbc4aa6872818906e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee81f07b82dc401eafef395f3093395e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f120077a5224f62a7d7252e2c3e2443",
       "placeholder": "​",
       "style": "IPY_MODEL_84128c0f43d64712a76e9cedc565107c",
       "value": " 557/557 [00:00&lt;00:00, 9.69kB/s]"
      }
     },
     "f1f625a156e446ebb25d2d36820b10f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fbb17d0b74b042a6bd46aa42168927a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
